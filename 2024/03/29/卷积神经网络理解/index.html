<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>卷积神经网络理解 | Missonix</title><meta name="author" content="Missonix"><meta name="copyright" content="Missonix"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="卷积网络深度影响感受野大小卷积网络的深度会影响感受野的大小，但“感受的区域”和“感受的图片尺寸”是不同的概念。感受野是指网络中某个神经元所看到的输入图像的局部区域的大小，而图片尺寸是指输入图像的实际大小。随着卷积层数的增加，感受野的大小会逐渐增大，能够感知到更大的图像区域，从而有助于学习到更全局的特征。 采样1. 上下采样与通道维度上下采样（空间维度操作）：传统意义上的上下采样（如池化、插值）主要">
<meta property="og:type" content="article">
<meta property="og:title" content="卷积神经网络理解">
<meta property="og:url" content="https://missonix.github.io/2024/03/29/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%90%86%E8%A7%A3/index.html">
<meta property="og:site_name" content="Missonix">
<meta property="og:description" content="卷积网络深度影响感受野大小卷积网络的深度会影响感受野的大小，但“感受的区域”和“感受的图片尺寸”是不同的概念。感受野是指网络中某个神经元所看到的输入图像的局部区域的大小，而图片尺寸是指输入图像的实际大小。随着卷积层数的增加，感受野的大小会逐渐增大，能够感知到更大的图像区域，从而有助于学习到更全局的特征。 采样1. 上下采样与通道维度上下采样（空间维度操作）：传统意义上的上下采样（如池化、插值）主要">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://missonix.github.io/img/Missonix.jpg">
<meta property="article:published_time" content="2024-03-29T00:26:13.000Z">
<meta property="article:modified_time" content="2025-02-24T16:16:33.864Z">
<meta property="article:author" content="Missonix">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="卷积神经网络">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://missonix.github.io/img/Missonix.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "卷积神经网络理解",
  "url": "https://missonix.github.io/2024/03/29/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%90%86%E8%A7%A3/",
  "image": "https://missonix.github.io/img/Missonix.jpg",
  "datePublished": "2024-03-29T00:26:13.000Z",
  "dateModified": "2025-02-24T16:16:33.864Z",
  "author": [
    {
      "@type": "Person",
      "name": "Missonix",
      "url": "https://missonix.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://missonix.github.io/2024/03/29/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%90%86%E8%A7%A3/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '卷积神经网络理解',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/Missonix.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">3</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Missonix</span></a><a class="nav-page-title" href="/"><span class="site-name">卷积神经网络理解</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">卷积神经网络理解</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-03-29T00:26:13.000Z" title="发表于 2024-03-29 08:26:13">2024-03-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-02-24T16:16:33.864Z" title="更新于 2025-02-25 00:16:33">2025-02-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="卷积网络深度影响感受野大小"><a href="#卷积网络深度影响感受野大小" class="headerlink" title="卷积网络深度影响感受野大小"></a>卷积网络深度影响感受野大小</h2><p>卷积网络的深度会影响感受野的大小，但“感受的区域”和“感受的图片尺寸”是不同的概念。感受野是指网络中某个神经元所看到的输入图像的局部区域的大小，而图片尺寸是指输入图像的实际大小。<br>随着卷积层数的增加，感受野的大小会逐渐增大，能够感知到更大的图像区域，从而有助于学习到更全局的特征。</p>
<h2 id="采样"><a href="#采样" class="headerlink" title="采样"></a>采样</h2><h3 id="1-上下采样与通道维度"><a href="#1-上下采样与通道维度" class="headerlink" title="1. 上下采样与通道维度"></a>1. 上下采样与通道维度</h3><p>上下采样（空间维度操作）：传统意义上的上下采样（如池化、插值）主要调整图像的空间分辨率（行、列），不直接改变通道数。例如：</p>
<p>最大池化（Max Pooling）：仅减小空间尺寸，通道数不变。</p>
<p>双线性插值上采样：仅增大空间尺寸，通道数不变。</p>
<p>通道维度的变化：通道的升降维通常通过卷积操作（如1×1卷积）实现，而不是上下采样本身。但某些操作（如步长卷积）可能同时改变空间尺寸和通道数。</p>
<h3 id="2-卷积与下采样的关系"><a href="#2-卷积与下采样的关系" class="headerlink" title="2. 卷积与下采样的关系"></a>2. 卷积与下采样的关系</h3><p>常规卷积（无下采样）：若卷积步长（stride）为1，且输入输出尺寸相同（通过填充padding），则不涉及下采样。</p>
<p>下采样卷积：若步长&gt;1（如stride&#x3D;2），或通过池化（如MaxPool2d），则空间分辨率降低（如尺寸减半），实现下采样。</p>
<p>通道数的调整：卷积核数量（即输出的通道数）可独立设置。例如：</p>
<p>输入尺寸 [B, C_in, H, W] → 使用k个卷积核 → 输出 [B, k, H&#x2F;s, W&#x2F;s]（s为步长）。</p>
<p>此时空间分辨率降低（下采样），通道数可能增加（升维）或减少（降维）。</p>
<h3 id="3-通道维度升降的机制"><a href="#3-通道维度升降的机制" class="headerlink" title="3. 通道维度升降的机制"></a>3. 通道维度升降的机制</h3><p>通道升降维的核心方法：</p>
<p>卷积操作：通过调整卷积核数量（如从64个核变为128个核）改变通道数。</p>
<p>1×1卷积：专门用于通道维度的升&#x2F;降维（如ResNet中的“瓶颈结构”）。</p>
<p>全连接层（FC）：在某些网络（如VGG）中，FC层可能间接改变通道维度。</p>
<p>通道升维的目的：增加特征多样性，允许网络学习更复杂的特征组合（如不同通道对应不同边缘方向、颜色模式等）。</p>
<h3 id="4-下采样的目的"><a href="#4-下采样的目的" class="headerlink" title="4. 下采样的目的"></a>4. 下采样的目的</h3><p>关键作用：</p>
<p>扩大感受野（Receptive Field）：通过降低分辨率，后续层的每个神经元能覆盖输入图像的更大区域，从而捕捉全局特征。</p>
<p>减少计算量：空间尺寸减半可使计算量减少约4倍（面积平方关系）。</p>
<p>参数压缩与抽象化：通过逐层下采样，迫使网络逐步忽略局部细节，提取更高层次的语义特征（如从“边缘”到“物体部件”再到“完整物体”）。</p>
<h3 id="5-通道升维的目的"><a href="#5-通道升维的目的" class="headerlink" title="5. 通道升维的目的"></a>5. 通道升维的目的</h3><p>特征空间的扩展：</p>
<p>低维→高维：通过增加通道数，允许网络在不同通道中学习互补的特征（如颜色、纹理、形状）。</p>
<p>特征交互：多通道间的非线性组合（通过激活函数）能增强模型的表达能力（如SENet中的通道注意力）。</p>
<h3 id="6-网络架构的典型设计"><a href="#6-网络架构的典型设计" class="headerlink" title="6. 网络架构的典型设计"></a>6. 网络架构的典型设计</h3><p>经典模式：</p>
<p>编码器（Encoder）：逐步下采样（降低分辨率）并升维（增加通道数），提取抽象特征。</p>
<p>解码器（Decoder）：逐步上采样（恢复分辨率）并降维（减少通道数），用于分割、生成等任务。</p>
<p>全连接层（FC）的替代：现代网络（如ResNet、Transformer）倾向于用全局平均池化（GAP）替代FC层，避免参数爆炸。</p>
<p>激活函数的应用：</p>
<p>Sigmoid通常用于二分类输出层（概率映射），而非中间特征提取。</p>
<p>中间层多用ReLU或其变体（如Leaky ReLU）防止梯度消失。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通道维度变化与卷积的绑定：下采样（空间缩减）和通道升维（特征丰富化）常通过步长&gt;1的卷积同时实现。</p>
<p>下采样与参数量的关系：下采样主要减少计算量，但参数量可能因通道数增加而上升（如ResNet中每层的通道数翻倍）。</p>
<p>末端结构：现代网络设计更倾向于使用GAP+1×1卷积替代FC层，以提高泛化能力。</p>
<h2 id="卷积核"><a href="#卷积核" class="headerlink" title="卷积核"></a>卷积核</h2><h3 id="1-所有卷积核（如3×3、5×5）都能实现通道升维和下采样吗？"><a href="#1-所有卷积核（如3×3、5×5）都能实现通道升维和下采样吗？" class="headerlink" title="1. 所有卷积核（如3×3、5×5）都能实现通道升维和下采样吗？"></a>1. 所有卷积核（如3×3、5×5）都能实现通道升维和下采样吗？</h3><p>无论卷积核尺寸如何，通道数的调整由卷积核的数量决定，而下采样由步长（stride）控制。例如：</p>
<p>输入尺寸：[B, C_in, H, W]</p>
<p>卷积操作：使用 k 个尺寸为 K×K 的卷积核，步长 s</p>
<p>输出尺寸：[B, k, H&#x2F;s, W&#x2F;s]</p>
<p>无论 K 是1、3还是5，只要满足：</p>
<p>通道升维：k &gt; C_in（输出通道数 &gt; 输入通道数）</p>
<p>下采样：s &gt; 1（步长 &gt;1，如s&#x3D;2时分辨率减半）</p>
<p>则任意尺寸的卷积核均可同时实现通道升维和下采样。</p>
<h3 id="2-步长-1是否更快实现下采样？"><a href="#2-步长-1是否更快实现下采样？" class="headerlink" title="2. 步长&gt;1是否更快实现下采样？"></a>2. 步长&gt;1是否更快实现下采样？</h3><p>步长是控制下采样速度的关键参数：</p>
<p>步长&#x3D;1：需结合池化（如MaxPool2d）才能下采样。</p>
<p>步长&gt;1：直接通过卷积一步完成下采样（更高效）。</p>
<p>示例：</p>
<p>输入尺寸 [H, W] &#x3D; [224, 224]</p>
<p>使用3×3卷积，步长&#x3D;2 → 输出尺寸 [112, 112]（下采样速度比步长&#x3D;1快一倍）。</p>
<h3 id="3-不同卷积核的核心用途与选择场景"><a href="#3-不同卷积核的核心用途与选择场景" class="headerlink" title="3.不同卷积核的核心用途与选择场景"></a>3.不同卷积核的核心用途与选择场景</h3><h4 id="1×1卷积核"><a href="#1×1卷积核" class="headerlink" title="1×1卷积核"></a>1×1卷积核</h4><p>核心作用：</p>
<p>通道维度调整：升维（增加特征多样性）或降维（减少计算量）。</p>
<p>跨通道特征融合：通过线性组合不同通道的特征（类似全连接层的局部作用）。</p>
<p>优势：</p>
<p>零空间信息损失：不改变特征图的空间尺寸（步长&#x3D;1时）。</p>
<p>极低的计算量：参数量仅为 C_in × C_out（远小于3×3卷积）。</p>
<p>典型场景：</p>
<p>通道降维：如ResNet的“瓶颈结构”（输入256通道 → 1×1卷积→64通道 → 3×3卷积→64通道 → 1×1卷积→256通道）。</p>
<p>特征融合：如Inception模块中混合不同分支的特征。</p>
<p>轻量化设计：MobileNet用1×1卷积替代全连接层。</p>
<h4 id="3×3卷积核"><a href="#3×3卷积核" class="headerlink" title="3×3卷积核"></a>3×3卷积核</h4><p>核心作用：</p>
<p>空间特征提取：捕捉局部空间模式（如边缘、纹理）。</p>
<p>高效感受野扩展：多个3×3卷积堆叠等效于更大卷积核（如2个3×3 ≈ 5×5感受野）。</p>
<p>优势：</p>
<p>平衡计算量与性能：参数量为 C_in × C_out × 3×3，在多数任务中性价比最高。</p>
<p>典型场景：</p>
<p>基础特征提取：如VGG、ResNet的主干网络。</p>
<p>步长&#x3D;2的下采样：直接通过卷积完成分辨率降低和通道升维。</p>
<h4 id="5×5或更大卷积核"><a href="#5×5或更大卷积核" class="headerlink" title="5×5或更大卷积核"></a>5×5或更大卷积核</h4><p>核心作用：</p>
<p>大感受野特征提取：直接覆盖更大区域，捕捉全局上下文。</p>
<p>劣势：</p>
<p>计算量大：参数量为 C_in × C_out × 5×5，是3×3的约2.8倍。</p>
<p>易过拟合：参数量大时需更多数据支撑。</p>
<p>典型场景：</p>
<p>早期网络设计：如AlexNet的第一层（11×11卷积）。</p>
<p>特定任务需求：如检测任务中需大感受野捕捉远距离关联。</p>
<h3 id="4-不同卷积核的选择策略"><a href="#4-不同卷积核的选择策略" class="headerlink" title="4. 不同卷积核的选择策略"></a>4. 不同卷积核的选择策略</h3><h4 id="优先使用3×3卷积"><a href="#优先使用3×3卷积" class="headerlink" title="优先使用3×3卷积"></a>优先使用3×3卷积</h4><p>原因：</p>
<p>多个3×3卷积堆叠可等效更大卷积核的感受野，但参数量更低（如2层3×3参数量为 2×3²&#x3D;18，1层5×5参数量为 25）。</p>
<p>更深的非线性激活（每层后接ReLU）增强模型表达能力。</p>
<h4 id="需要通道调整时用1×1卷积"><a href="#需要通道调整时用1×1卷积" class="headerlink" title="需要通道调整时用1×1卷积"></a>需要通道调整时用1×1卷积</h4><p>示例：</p>
<p>升维：从64通道→256通道，使用1×1卷积（步长&#x3D;1）。</p>
<p>降维：从256通道→64通道，减少后续3×3卷积的计算量。</p>
<h4 id="大卷积核的替代方案"><a href="#大卷积核的替代方案" class="headerlink" title="大卷积核的替代方案"></a>大卷积核的替代方案</h4><p>空洞卷积（Dilated Convolution）：扩大感受野不增加参数量。</p>
<p>空间注意力机制：动态关注重要区域，替代固定的大卷积核。</p>
<h3 id="5-经典网络中的设计实例"><a href="#5-经典网络中的设计实例" class="headerlink" title="5.经典网络中的设计实例"></a>5.经典网络中的设计实例</h3><h4 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h4><p>残差块：使用1×1卷积调整通道数，3×3卷积提取特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ResNet的Bottleneck结构</span></span><br><span class="line">conv1x1(<span class="number">64</span>→<span class="number">256</span>) → conv3x3(<span class="number">256</span>→<span class="number">256</span>) → conv1x1(<span class="number">256</span>→<span class="number">1024</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Inception-v4"><a href="#Inception-v4" class="headerlink" title="Inception-v4"></a>Inception-v4</h4><p>混合卷积核：并行使用1×1、3×3、5×5卷积，融合多尺度特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Inception模块</span></span><br><span class="line">branch1 = conv1x1(<span class="number">64</span>)</span><br><span class="line">branch2 = conv1x1(<span class="number">64</span>) → conv3x3(<span class="number">64</span>)</span><br><span class="line">branch3 = conv1x1(<span class="number">64</span>) → conv5x5(<span class="number">64</span>)</span><br><span class="line">branch4 = MaxPool → conv1x1(<span class="number">64</span>)</span><br><span class="line">concat([branch1, branch2, branch3, branch4])</span><br></pre></td></tr></table></figure>

<h4 id="MobileNet"><a href="#MobileNet" class="headerlink" title="MobileNet"></a>MobileNet</h4><p>深度可分离卷积：先用3×3卷积提取空间特征（通道分离），再用1×1卷积融合通道。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 深度可分离卷积</span></span><br><span class="line">depthwise_conv3x3(C_in→C_in, groups=C_in) → conv1x1(C_in→C_out)</span><br></pre></td></tr></table></figure>

<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>所有卷积核均可实现通道升降维和下采样，但不同尺寸的卷积核各有侧重：</p>
<p>1×1卷积：纯通道操作，轻量化调整。</p>
<p>3×3&#x2F;5×5卷积：空间特征提取 + 通道调整。</p>
<p>步长&gt;1的卷积是最高效的下采样方式（一步完成分辨率降低和通道调整）。</p>
<p>设计建议：</p>
<p>优先使用3×3卷积作为主干。</p>
<p>用1×1卷积控制通道数和计算量。</p>
<p>仅在需要大感受野且计算资源充足时使用5×5或更大卷积核。</p>
<h2 id="1-1的卷积的作用核心："><a href="#1-1的卷积的作用核心：" class="headerlink" title="1*1的卷积的作用核心："></a>1*1的卷积的作用核心：</h2><p>表面是是做了通道的切换，实际上是做了特征的组合生成更复杂的特征表示(通道降维)，特征的分离将复杂的特征分离成几个独立的特征(通道升维)</p>
<h3 id="1×1卷积的核心目的"><a href="#1×1卷积的核心目的" class="headerlink" title="1×1卷积的核心目的"></a>1×1卷积的核心目的</h3><h4 id="1-通道维度的灵活调整"><a href="#1-通道维度的灵活调整" class="headerlink" title="1. 通道维度的灵活调整"></a>1. 通道维度的灵活调整</h4><p>降维（减少通道数）：</p>
<p>降低计算复杂度：假设输入为256通道，通过1×1卷积输出64通道，后续的3×3卷积计算量将减少为原来的1&#x2F;4（从256×3×3到64×3×3）。</p>
<p>压缩冗余信息：迫使网络通过少量通道保留关键特征（类似“信息蒸馏”）。</p>
<p>升维（增加通道数）：</p>
<p>扩展特征多样性：为后续层提供更多特征组合的可能性（如不同通道可对应不同抽象层次的特征）。</p>
<p>跨通道交互：通过线性组合不同通道的信息，生成更复杂的特征表示（如颜色+纹理的组合）。</p>
<h4 id="2-跨通道特征融合"><a href="#2-跨通道特征融合" class="headerlink" title="2. 跨通道特征融合"></a>2. 跨通道特征融合</h4><p>线性组合的威力：1×1卷积本质是对所有输入通道的加权求和，输出通道的每个值都是输入通道的全局组合。例如：</p>
<p>输入通道可能分别对应“红色边缘”“蓝色纹理”“绿色斑点”，1×1卷积可以生成“红-蓝组合边缘”“蓝-绿组合纹理”等新特征。</p>
<p>非线性激活前的准备：通过1×1卷积的线性组合，后续的非线性激活（如ReLU）能更高效地捕获复杂模式。</p>
<h4 id="3-网络结构的灵活性"><a href="#3-网络结构的灵活性" class="headerlink" title="3. 网络结构的灵活性"></a>3. 网络结构的灵活性</h4><p>构建“瓶颈”结构（如ResNet）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ResNet Bottleneck</span></span><br><span class="line">输入<span class="number">256</span>通道 → <span class="number">1</span>×<span class="number">1</span>卷积降维至<span class="number">64</span>通道 → <span class="number">3</span>×<span class="number">3</span>卷积处理 → <span class="number">1</span>×<span class="number">1</span>卷积升维回<span class="number">256</span>通道</span><br><span class="line">目的：减少中间<span class="number">3</span>×<span class="number">3</span>卷积的计算量，同时保持输入输出通道一致以支持残差连接。</span><br></pre></td></tr></table></figure>

<h3 id="1×1卷积为何不改变空间尺寸？"><a href="#1×1卷积为何不改变空间尺寸？" class="headerlink" title="1×1卷积为何不改变空间尺寸？"></a>1×1卷积为何不改变空间尺寸？</h3><p>数学操作特性：</p>
<p>卷积核尺寸&#x3D;1×1：每个输出位置仅与输入中同一位置的1×1区域相关，不涉及周围像素。</p>
<p>步长（stride）&#x3D;1：滑动步长为1，确保输出尺寸与输入相同。</p>
<p>填充（padding）&#x3D;0或1：通常通过填充（如padding&#x3D;0）保持尺寸不变。</p>
<p>空间信息的保留：</p>
<p>由于不进行空间聚合（如3×3卷积会混合邻域像素），1×1卷积完全保留原始空间结构，仅操作通道维度。</p>
<h3 id="是否违背信息守恒定律？"><a href="#是否违背信息守恒定律？" class="headerlink" title="是否违背信息守恒定律？"></a>是否违背信息守恒定律？</h3><p>信息守恒的误解：</p>
<p>信息并未丢失，而是重新编码：1×1卷积通过权重矩阵将输入通道的信息投影到新的通道空间中。例如：</p>
<p>输入通道数为3（RGB），通过1×1卷积升维至64通道，每个输出通道是3个原始通道的加权和。</p>
<p>可逆性：若权重矩阵满秩且输出通道数≥输入通道数，理论上可通过另一个1×1卷积还原原始信息（但实际中网络通过训练优化权重，选择性地保留有用信息）。</p>
<p>类似PCA的降维思想：</p>
<p>降维时，1×1卷积类似主成分分析（PCA），通过线性变换保留主要特征，舍弃次要信息（但参数是数据驱动学习而非固定）。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://missonix.github.io">Missonix</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://missonix.github.io/2024/03/29/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%90%86%E8%A7%A3/">https://missonix.github.io/2024/03/29/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%90%86%E8%A7%A3/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://missonix.github.io" target="_blank">Missonix</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">卷积神经网络</a><a class="post-meta__tags" href="/tags/AI/">AI</a></div><div class="post-share"><div class="social-share" data-image="/img/Missonix.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2024/03/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" title="机器学习基础"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">机器学习基础</div></div><div class="info-2"><div class="info-item-1">...</div></div></div></a><a class="pagination-related" href="/2025/01/26/LangChain%E5%9F%BA%E7%A1%80%E4%B8%8ERAG-Agent%E5%BC%80%E5%8F%91/" title="LangChain基础与RAG Agent开发"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">LangChain基础与RAG Agent开发</div></div><div class="info-2"><div class="info-item-1">LangChain与RAG完整开发指南一、LangChain核心组件1.1 模型实例化123456789# 模型调用示例from langchain_openai import ChatOpenAImodel = ChatOpenAI(    openai_api_key=&quot;sk-xxx&quot;,    openai_api_base=&quot;https://api.moonshot.cn/v1&quot;,  # 支持国内模型    model_name=&quot;moonshot-v1-8k&quot;,    temperature=0.7,  # 控制生成随机性（0-1）    streaming=True    # 启用流式响应) 关键参数说明：  model_name: 支持主流模型如gpt-4、moonshot系列等 temperature: 值越大生成结果越随机 max_tokens: 控制生成内容的最大长度   1.2 提示词模板PromptTemplate 最基础的模板123456from langchain_core.prompts...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2024/03/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" title="机器学习基础"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-28</div><div class="info-item-2">机器学习基础</div></div><div class="info-2"><div class="info-item-1">...</div></div></div></a><a class="pagination-related" href="/2025/01/26/LangChain%E5%9F%BA%E7%A1%80%E4%B8%8ERAG-Agent%E5%BC%80%E5%8F%91/" title="LangChain基础与RAG Agent开发"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-26</div><div class="info-item-2">LangChain基础与RAG Agent开发</div></div><div class="info-2"><div class="info-item-1">LangChain与RAG完整开发指南一、LangChain核心组件1.1 模型实例化123456789# 模型调用示例from langchain_openai import ChatOpenAImodel = ChatOpenAI(    openai_api_key=&quot;sk-xxx&quot;,    openai_api_base=&quot;https://api.moonshot.cn/v1&quot;,  # 支持国内模型    model_name=&quot;moonshot-v1-8k&quot;,    temperature=0.7,  # 控制生成随机性（0-1）    streaming=True    # 启用流式响应) 关键参数说明：  model_name: 支持主流模型如gpt-4、moonshot系列等 temperature: 值越大生成结果越随机 max_tokens: 控制生成内容的最大长度   1.2 提示词模板PromptTemplate 最基础的模板123456from langchain_core.prompts...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/Missonix.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Missonix</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">3</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/Missonix" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:ackerman0919@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E6%B7%B1%E5%BA%A6%E5%BD%B1%E5%93%8D%E6%84%9F%E5%8F%97%E9%87%8E%E5%A4%A7%E5%B0%8F"><span class="toc-number">1.</span> <span class="toc-text">卷积网络深度影响感受野大小</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%87%E6%A0%B7"><span class="toc-number">2.</span> <span class="toc-text">采样</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%B8%8A%E4%B8%8B%E9%87%87%E6%A0%B7%E4%B8%8E%E9%80%9A%E9%81%93%E7%BB%B4%E5%BA%A6"><span class="toc-number">2.1.</span> <span class="toc-text">1. 上下采样与通道维度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%8D%B7%E7%A7%AF%E4%B8%8E%E4%B8%8B%E9%87%87%E6%A0%B7%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">2.2.</span> <span class="toc-text">2. 卷积与下采样的关系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E9%80%9A%E9%81%93%E7%BB%B4%E5%BA%A6%E5%8D%87%E9%99%8D%E7%9A%84%E6%9C%BA%E5%88%B6"><span class="toc-number">2.3.</span> <span class="toc-text">3. 通道维度升降的机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E4%B8%8B%E9%87%87%E6%A0%B7%E7%9A%84%E7%9B%AE%E7%9A%84"><span class="toc-number">2.4.</span> <span class="toc-text">4. 下采样的目的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E9%80%9A%E9%81%93%E5%8D%87%E7%BB%B4%E7%9A%84%E7%9B%AE%E7%9A%84"><span class="toc-number">2.5.</span> <span class="toc-text">5. 通道升维的目的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E7%9A%84%E5%85%B8%E5%9E%8B%E8%AE%BE%E8%AE%A1"><span class="toc-number">2.6.</span> <span class="toc-text">6. 网络架构的典型设计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">2.7.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E6%A0%B8"><span class="toc-number">3.</span> <span class="toc-text">卷积核</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%89%80%E6%9C%89%E5%8D%B7%E7%A7%AF%E6%A0%B8%EF%BC%88%E5%A6%823%C3%973%E3%80%815%C3%975%EF%BC%89%E9%83%BD%E8%83%BD%E5%AE%9E%E7%8E%B0%E9%80%9A%E9%81%93%E5%8D%87%E7%BB%B4%E5%92%8C%E4%B8%8B%E9%87%87%E6%A0%B7%E5%90%97%EF%BC%9F"><span class="toc-number">3.1.</span> <span class="toc-text">1. 所有卷积核（如3×3、5×5）都能实现通道升维和下采样吗？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%AD%A5%E9%95%BF-1%E6%98%AF%E5%90%A6%E6%9B%B4%E5%BF%AB%E5%AE%9E%E7%8E%B0%E4%B8%8B%E9%87%87%E6%A0%B7%EF%BC%9F"><span class="toc-number">3.2.</span> <span class="toc-text">2. 步长&gt;1是否更快实现下采样？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E4%B8%8D%E5%90%8C%E5%8D%B7%E7%A7%AF%E6%A0%B8%E7%9A%84%E6%A0%B8%E5%BF%83%E7%94%A8%E9%80%94%E4%B8%8E%E9%80%89%E6%8B%A9%E5%9C%BA%E6%99%AF"><span class="toc-number">3.3.</span> <span class="toc-text">3.不同卷积核的核心用途与选择场景</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%C3%971%E5%8D%B7%E7%A7%AF%E6%A0%B8"><span class="toc-number">3.3.1.</span> <span class="toc-text">1×1卷积核</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%C3%973%E5%8D%B7%E7%A7%AF%E6%A0%B8"><span class="toc-number">3.3.2.</span> <span class="toc-text">3×3卷积核</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5%C3%975%E6%88%96%E6%9B%B4%E5%A4%A7%E5%8D%B7%E7%A7%AF%E6%A0%B8"><span class="toc-number">3.3.3.</span> <span class="toc-text">5×5或更大卷积核</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E4%B8%8D%E5%90%8C%E5%8D%B7%E7%A7%AF%E6%A0%B8%E7%9A%84%E9%80%89%E6%8B%A9%E7%AD%96%E7%95%A5"><span class="toc-number">3.4.</span> <span class="toc-text">4. 不同卷积核的选择策略</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%85%88%E4%BD%BF%E7%94%A83%C3%973%E5%8D%B7%E7%A7%AF"><span class="toc-number">3.4.1.</span> <span class="toc-text">优先使用3×3卷积</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E8%A6%81%E9%80%9A%E9%81%93%E8%B0%83%E6%95%B4%E6%97%B6%E7%94%A81%C3%971%E5%8D%B7%E7%A7%AF"><span class="toc-number">3.4.2.</span> <span class="toc-text">需要通道调整时用1×1卷积</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%A7%E5%8D%B7%E7%A7%AF%E6%A0%B8%E7%9A%84%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%A1%88"><span class="toc-number">3.4.3.</span> <span class="toc-text">大卷积核的替代方案</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%AE%9E%E4%BE%8B"><span class="toc-number">3.5.</span> <span class="toc-text">5.经典网络中的设计实例</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#ResNet"><span class="toc-number">3.5.1.</span> <span class="toc-text">ResNet</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Inception-v4"><span class="toc-number">3.5.2.</span> <span class="toc-text">Inception-v4</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MobileNet"><span class="toc-number">3.5.3.</span> <span class="toc-text">MobileNet</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-1"><span class="toc-number">3.6.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1%E7%9A%84%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%BD%9C%E7%94%A8%E6%A0%B8%E5%BF%83%EF%BC%9A"><span class="toc-number">4.</span> <span class="toc-text">1*1的卷积的作用核心：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%C3%971%E5%8D%B7%E7%A7%AF%E7%9A%84%E6%A0%B8%E5%BF%83%E7%9B%AE%E7%9A%84"><span class="toc-number">4.1.</span> <span class="toc-text">1×1卷积的核心目的</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E9%80%9A%E9%81%93%E7%BB%B4%E5%BA%A6%E7%9A%84%E7%81%B5%E6%B4%BB%E8%B0%83%E6%95%B4"><span class="toc-number">4.1.1.</span> <span class="toc-text">1. 通道维度的灵活调整</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E8%B7%A8%E9%80%9A%E9%81%93%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88"><span class="toc-number">4.1.2.</span> <span class="toc-text">2. 跨通道特征融合</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E7%9A%84%E7%81%B5%E6%B4%BB%E6%80%A7"><span class="toc-number">4.1.3.</span> <span class="toc-text">3. 网络结构的灵活性</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1%C3%971%E5%8D%B7%E7%A7%AF%E4%B8%BA%E4%BD%95%E4%B8%8D%E6%94%B9%E5%8F%98%E7%A9%BA%E9%97%B4%E5%B0%BA%E5%AF%B8%EF%BC%9F"><span class="toc-number">4.2.</span> <span class="toc-text">1×1卷积为何不改变空间尺寸？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%98%AF%E5%90%A6%E8%BF%9D%E8%83%8C%E4%BF%A1%E6%81%AF%E5%AE%88%E6%81%92%E5%AE%9A%E5%BE%8B%EF%BC%9F"><span class="toc-number">4.3.</span> <span class="toc-text">是否违背信息守恒定律？</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/01/26/LangChain%E5%9F%BA%E7%A1%80%E4%B8%8ERAG-Agent%E5%BC%80%E5%8F%91/" title="LangChain基础与RAG Agent开发">LangChain基础与RAG Agent开发</a><time datetime="2025-01-26T15:01:13.000Z" title="发表于 2025-01-26 23:01:13">2025-01-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/03/29/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%90%86%E8%A7%A3/" title="卷积神经网络理解">卷积神经网络理解</a><time datetime="2024-03-29T00:26:13.000Z" title="发表于 2024-03-29 08:26:13">2024-03-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/03/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" title="机器学习基础">机器学习基础</a><time datetime="2024-03-28T11:45:13.000Z" title="发表于 2024-03-28 19:45:13">2024-03-28</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Missonix</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.3</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div></div></body></html>