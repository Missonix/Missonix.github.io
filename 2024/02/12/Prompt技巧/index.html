<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Prompt技巧 | Missonix</title><meta name="author" content="Missonix"><meta name="copyright" content="Missonix"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="驾驭大语言模型：高质量提示词（Prompt）撰写指南一、引言：深入理解提示词（Prompt）的价值A. 提示词的定义及其在大模型交互中的核心作用提示词（Prompt）是一种基于人工智能（AI）指令的技术，它通过明确而具体的指导，引导大语言模型（LLM）的输出。在用户与LLM的交互过程中，提示词扮演着桥梁的角色，是激发模型产生特定回应的关键输入。它并非简单的问句或指令的堆砌，而是包含了用户意图、任务">
<meta property="og:type" content="article">
<meta property="og:title" content="Prompt技巧">
<meta property="og:url" content="https://missonix.github.io/2024/02/12/Prompt%E6%8A%80%E5%B7%A7/index.html">
<meta property="og:site_name" content="Missonix">
<meta property="og:description" content="驾驭大语言模型：高质量提示词（Prompt）撰写指南一、引言：深入理解提示词（Prompt）的价值A. 提示词的定义及其在大模型交互中的核心作用提示词（Prompt）是一种基于人工智能（AI）指令的技术，它通过明确而具体的指导，引导大语言模型（LLM）的输出。在用户与LLM的交互过程中，提示词扮演着桥梁的角色，是激发模型产生特定回应的关键输入。它并非简单的问句或指令的堆砌，而是包含了用户意图、任务">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://missonix.github.io/img/Missonix.jpg">
<meta property="article:published_time" content="2024-02-12T03:02:58.000Z">
<meta property="article:modified_time" content="2025-05-12T15:07:52.524Z">
<meta property="article:author" content="Missonix">
<meta property="article:tag" content="Prompt">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://missonix.github.io/img/Missonix.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Prompt技巧",
  "url": "https://missonix.github.io/2024/02/12/Prompt%E6%8A%80%E5%B7%A7/",
  "image": "https://missonix.github.io/img/Missonix.jpg",
  "datePublished": "2024-02-12T03:02:58.000Z",
  "dateModified": "2025-05-12T15:07:52.524Z",
  "author": [
    {
      "@type": "Person",
      "name": "Missonix",
      "url": "https://missonix.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://missonix.github.io/2024/02/12/Prompt%E6%8A%80%E5%B7%A7/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Prompt技巧',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/Missonix.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">9</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">22</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Missonix</span></a><a class="nav-page-title" href="/"><span class="site-name">Prompt技巧</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Prompt技巧</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-02-12T03:02:58.000Z" title="发表于 2024-02-12 11:02:58">2024-02-12</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-05-12T15:07:52.524Z" title="更新于 2025-05-12 23:07:52">2025-05-12</time></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="驾驭大语言模型：高质量提示词（Prompt）撰写指南"><a href="#驾驭大语言模型：高质量提示词（Prompt）撰写指南" class="headerlink" title="驾驭大语言模型：高质量提示词（Prompt）撰写指南"></a>驾驭大语言模型：高质量提示词（Prompt）撰写指南</h1><h2 id="一、引言：深入理解提示词（Prompt）的价值"><a href="#一、引言：深入理解提示词（Prompt）的价值" class="headerlink" title="一、引言：深入理解提示词（Prompt）的价值"></a>一、引言：深入理解提示词（Prompt）的价值</h2><h3 id="A-提示词的定义及其在大模型交互中的核心作用"><a href="#A-提示词的定义及其在大模型交互中的核心作用" class="headerlink" title="A. 提示词的定义及其在大模型交互中的核心作用"></a>A. 提示词的定义及其在大模型交互中的核心作用</h3><p>提示词（Prompt）是一种基于人工智能（AI）指令的技术，它通过明确而具体的指导，引导大语言模型（LLM）的输出。在用户与LLM的交互过程中，提示词扮演着桥梁的角色，是激发模型产生特定回应的关键输入。它并非简单的问句或指令的堆砌，而是包含了用户意图、任务描述、上下文信息以及对输出形式期望的综合体。提示词的质量直接决定了LLM输出内容的优劣、相关程度和准确性。一个精心设计的提示词能够充分发掘并引导LLM的强大潜力，使其生成符合预期的、高质量的文本、代码或其他形式的内容。反之，一个模糊不清或结构混乱的提示词，则极易导致模型产生无用甚至错误的输出，从而大大降低LLM的实用价值。</p>
<p>无论是个人用户在日常工作学习中运用LLM进行信息提取、报告总结、文本创作，还是企业在构建智能客服、销售助手、新一代知识库等复杂应用时，提示词都发挥着至关重要的作用。它定义了LLM理解任务的起点和执行任务的框架。</p>
<h3 id="B-高质量提示词对于提升大模型输出效果的重要性"><a href="#B-高质量提示词对于提升大模型输出效果的重要性" class="headerlink" title="B. 高质量提示词对于提升大模型输出效果的重要性"></a>B. 高质量提示词对于提升大模型输出效果的重要性</h3><p>大语言模型输出结果的质量，与其接收到的提示词中所蕴含信息的数量和完善程度密切相关。有效的提示词设计，能够精确地引导AI的内部推理路径和最终结果的生成方式。高质量的提示词能够帮助模型更准确地理解用户的真实意图，从而显著减少模型产生“幻觉”（即生成看似合理但与事实不符或与输入无关的内容）的现象，并促使其生成更为准确、更具相关性且更贴近用户期望的输出。这一点，在对可靠性有极高要求的应用场景中，例如金融风险评估、医疗诊断辅助等，其重要性尤为突出。</p>
<p>深入探究，提示工程（Prompt Engineering）已不仅仅是一种“提问的艺术”，更发展成为一门需要深刻理解模型能力边界、准确把握任务需求，并能将复杂的人类意图巧妙转化为模型可清晰理解和执行的指令的“科学”。LLM本质上是基于其海量训练数据中的模式进行匹配和概率预测的系统。提示词为LLM的这种模式匹配和预测行为提供了初始的上下文信息和关键的约束条件。一个高质量的提示词，通过其清晰性、具体性和无歧义性，能够为模型提供更为优质的上下文和约束。其结果是，模型在生成回应时，其内在的随机性和不确定性得到有效控制，从而更有可能收敛到用户所期望的输出。因此，提升与LLM交互的质量，并不仅仅依赖于模型本身的进化，更在很大程度上取决于用户或开发者构建和运用高质量提示词的能力。这实际上是将一部分确保输出质量的责任，从模型端转移到了提示词的设计端。</p>
<h2 id="二、高质量提示词的基石：核心要素与基本原则"><a href="#二、高质量提示词的基石：核心要素与基本原则" class="headerlink" title="二、高质量提示词的基石：核心要素与基本原则"></a>二、高质量提示词的基石：核心要素与基本原则</h2><h3 id="A-定义与衡量：什么是“高质量”的提示词？"><a href="#A-定义与衡量：什么是“高质量”的提示词？" class="headerlink" title="A. 定义与衡量：什么是“高质量”的提示词？"></a>A. 定义与衡量：什么是“高质量”的提示词？</h3><p>一个“高质量”的提示词，是能够引导大语言模型产出准确、相关、连贯且符合特定预期（如格式、风格、长度等）输出的指令集合。它通常具备清晰、具体、信息充分、结构良好等特征。所谓“高质量”，并非仅仅是用户的主观感受，而是可以通过一系列客观或半客观的指标来衡量，例如模型输出的准确性（Accuracy）、相关性（Relevance）、一致性（Consistency）、流畅性（Fluency）、遵循指令的程度（Adherence to Instructions）以及生成效率（Efficiency）等。</p>
<p>从更深层次理解，高质量提示词的本质在于最大限度地减少模型在理解用户意图时可能产生的“猜测空间”，并为其提供一条清晰、明确的路径指引，以达到期望的输出。大语言模型的输出行为天然带有机率性，这意味着即使是相同的输入，也可能产生不完全一致的输出。模糊、不完整或结构混乱的提示词会加剧这种不确定性，迫使模型在更为广阔的可能性空间中漫无目的地搜索答案。相反，一个高质量的提示词通过明确任务目标、提供充足上下文、设定必要约束、给出格式范例等方式，有效地收窄了模型的搜索范围和选择空间。这使得模型在生成回应时，能够更大概率地、更精确地收敛到用户真正期望的那一类输出上。因此，撰写高质量提示词的过程，可以看作是针对一个概率系统进行约束优化和歧义消除的工程实践。</p>
<h3 id="B-提示词的关键组成部分详解"><a href="#B-提示词的关键组成部分详解" class="headerlink" title="B. 提示词的关键组成部分详解"></a>B. 提示词的关键组成部分详解</h3><p>一个结构完善、信息充分的提示词通常包含以下几个关键组成部分。这些部分并非孤立存在，而是相互作用，共同构成一个完整的“指令包”，协同引导模型的行为。对这些要素的恰当组合与平衡，是适应不同任务和模型特性的关键。</p>
<ol>
<li>角色（Persona&#x2F;Role）：赋予模型特定身份<br>提示词可以明确指示模型扮演一个特定的角色或具备某种身份，例如“资深行业分析师”、“富有创意的广告文案撰写人”、“Linux终端”或“专业的英语翻译员”。为模型设定角色，有助于其调整回答的语气、风格、专业知识的深度和广度以及观察问题的视角，从而使得输出内容更贴合特定场景的需求。例如，当要求模型扮演“数学老师”时，它会倾向于使用易于学生理解的术语和方式来解释复杂的数学概念。一个具体的例子是：“我要你充当linux终端。我将输入命令，你将回复终端应有的内容。”。</li>
<li>任务（Task）：明确模型需完成的目标<br>任务是提示词的核心，它清晰而简洁地陈述了用户希望模型生成什么内容或执行什么具体操作，例如“撰写报告”、“总结要点”、“回答问题”、“翻译文本”或“生成代码”。任务的明确性直接决定了模型行动的方向。例如：“我要你担任面试官。我将成为候选人，你将向我询问XX岗位的面试问题。”，或者“请撰写一篇关于人工智能在金融领域应用的深度分析报告。”</li>
<li>指令（Instructions）：提供具体的操作指南<br>指令部分包含了模型在完成指定任务时需要遵循的具体步骤、规则、约束条件或方法论。指令对任务的执行方式进行了细化和规范。例如，可以要求模型“按照重要性降序列出要点，每个要点不超过30字”，或者采用“思维链”方式进行推理，即“请一步一步地思考并解释你的推理过程”。一个在金融信息抽取场景下的指令可能是：“严格基于提供的文本进行信息抽取，禁止在答案中添加任何编造成分。”。</li>
<li>上下文（Context）：提供必要的背景信息<br>上下文包含了模型在执行任务时所需要了解和参考的背景知识、相关材料、数据源、先前的对话历史或其他相关情境信息。提供充足的上下文有助于模型更准确地理解任务所处的特定环境，消除潜在的歧义，并将其注意力限定在相关的知识范围内。例如，在进行金融领域的信息抽取任务时，明确指出“涉及的文本为金融监管机构发布的官方文件”就能提供重要的背景约束。一个典型的上下文应用是：“鉴于全球平均气温自前工业化时代以来已上升1摄氏度，请讨论这对海平面上升可能产生的潜在影响。”。</li>
<li>输入数据（Input Data）：模型处理的具体对象<br>输入数据是提示词中指定任务需要处理的具体文本、问题、代码片段、图像或其他形式的数据。它是模型执行任务时直接操作的对象。例如，在处理一份行政处罚决定书的信息抽取任务时，输入数据就是该决定书的全文内容。</li>
<li>输出格式（Output Format）：指定期望的呈现形式<br>输出格式部分明确规定了用户希望模型生成内容的具体格式、结构、风格、长度等要求。指定输出格式不仅能确保模型生成的结果符合用户的直接预期，也便于后续的程序化处理和应用集成。例如，可以要求模型“以JSON对象的形式输出结果，包含‘key1’和‘key2’两个字段”。</li>
<li>示例（Examples &#x2F; Few-shot）：提供模仿范本<br>在提示词中提供一个或多个与任务相关的输入和期望输出的配对样例（即“少样本提示”），可以极大地帮助模型理解任务的具体要求、期望的回答风格和输出质量。示例，尤其是少样本提示，能够显著提升模型在特定任务上的表现，即便模型并未针对该任务进行过专门的微调。它们通过具体范例清晰地展示了期望的输出格式和内容逻辑。例如，在情感分类任务中可以提供如下示例：“文本：这部电影太棒了！ &#x2F;&#x2F; 情感：积极 \n 文本：这个产品很糟糕。 &#x2F;&#x2F; 情感：消极 \n 文本：哇，那场演出真是太酷了！ &#x2F;&#x2F; 情感：积极 \n 文本：多么可怕的节目！ &#x2F;&#x2F; 情感：”。</li>
</ol>
<p>角色设定为模型的行为和知识范围奠定了基调。任务则明确了其核心目标。指令进一步细化了达成目标的路径和必须遵守的规则。上下文信息为模型提供了必要的环境参数，帮助其准确定位。输入数据是模型进行操作的具体对象。输出格式规范了最终结果的呈现方式。而示例则通过具体的范例，进一步校准模型的理解偏差和输出行为。正是这些要素的协同作用，使得大语言模型能够更精确地理解和高效地执行日益复杂的指令。因此，提示工程在某种程度上可以被视为为一位能力极强但有时过于“字面化”的助手设计一份详尽且结构清晰的“工作说明书”。这份说明书（即提示词）越全面、越结构化，最终的成果就越能符合预期。</p>
<h3 id="C-编写高效提示词的核心原则"><a href="#C-编写高效提示词的核心原则" class="headerlink" title="C. 编写高效提示词的核心原则"></a>C. 编写高效提示词的核心原则</h3><p>构建高质量的提示词，除了理解其核心构成要素外，还需遵循一系列基本原则。这些原则共同指向一个核心目标：最小化模型理解用户意图的成本，同时最大化指令执行的效率和准确性。它们是所有高级提示技巧得以有效发挥作用的基石。</p>
<ol>
<li>清晰性 (Clarity) 和具体性 (Specificity)：<br>提示词应使用清晰、明确、无歧义的语言进行表述，避免使用模糊或可能产生多种解释的词汇和句式。例如，对于长度的要求，应从“写长一点”或“写短一点”这样的模糊表述，改进为“请将内容限定在500字以上，800字以下”这样的具体指令。清晰且具体的指令能够直接有效地引导模型，显著减少其进行不必要猜测和产生不相关输出的可能性。一个典型的改进案例是，将模糊的“讲讲艺术”这样的指令，具体化为“请解释印象派绘画的核心特点，并列举三位具有代表性的印象派画家及其主要贡献。”。</li>
<li>提供完整信息和上下文 (Completeness and Context)：<br>当需要模型针对特定的对象、场景或主题生成内容时，务必在提示词中补充足够且完整的背景信息和上下文。充足的上下文信息能够帮助模型更好地理解任务的约束条件、目标范围以及相关的特定知识。例如，在请求模型讨论海平面上升的潜在后果时，提供“鉴于全球平均气温自前工业化时代以来已上升1摄氏度”这样的具体数据作为上下文，能引导模型给出更有针对性的分析。</li>
<li>简洁性 (Conciseness) 与避免冗余：<br>虽然清晰和具体有时可能意味着提示词内容会相对较长，但仍应努力确保语言的简洁易懂，避免不必要的冗余信息或“啰嗦”的表达。冗长且充斥无关信息的提示词，不仅可能增加模型的处理负担，还可能引入不必要的噪声，反而干扰模型的理解，降低输出质量。因此，在确保所有必要信息都已包含的前提下，力求表达的精炼是关键。例如，将“这款产品的描述应该写得相当简短，大概只需要几句话，并且不要写太多其他的东西”这样的描述，改进为“请用一个包含3到5个句子的段落来描述这款产品。”会更为高效。</li>
<li>正确的语法、用词与标点 (Correctness)：<br>确保提示词在语法、词汇选择和标点符号使用上准确无误，是基本要求。语法错误、用词不当或标点混乱都可能导致模型对指令产生误解，从而影响输出结果的准确性。</li>
<li>明确指示行动 (Action Verbs)：<br>在提示词中应使用明确的、指向具体行动的动词来指定期望模型执行的操作，例如“撰写”、“总结”、“分析”、“比较”、“生成”、“翻译”等。这些行动动词能够直接、清晰地告知模型需要完成什么样的任务。例如：“请撰写一份关于最新研究发现的要点清单。”。</li>
<li>积极指令优于消极指令 (Positive Framing)：<br>通常情况下，直接告诉模型“做什么”比告诉它“不做什么”更为有效。消极指令，如“不要在回答中包含X方面的内容”，有时反而可能使模型的注意力不恰当地聚焦于X。积极指令则为模型提供了更直接、更清晰的行动方向。例如，与其说“不要询问用户名或密码”，不如更清晰地指示：“客服代表应尝试诊断问题并提出解决方案，同时避免询问任何与个人身份信息（PII）相关的问题。当需要用户信息时，应引导用户参考帮助文档<a target="_blank" rel="noopener" href="http://www.samplewebsite.com/help/faq%EF%BC%8C%E8%80%8C%E4%B8%8D%E6%98%AF%E7%9B%B4%E6%8E%A5%E7%B4%A2%E5%8F%96%E7%94%A8%E6%88%B7%E5%90%8D%E6%88%96%E5%AF%86%E7%A0%81%E7%AD%89PII%E3%80%82%E2%80%9D%E3%80%82">www.samplewebsite.com/help/faq，而不是直接索取用户名或密码等PII。”。</a></li>
<li>强调关键信息 (Emphasis)：<br>为了确保模型不会忽略提示中的核心要求，特别是当提示词较长或指令较为复杂时，可以通过重复关键词、使用大写字母、特殊格式（如引号、星号）或在指令末尾重申等方式来强调重要的部分。例如，在要求模型生成营销策略时，可以强调：“请重点突出能够有效提升用户参与度的营销策略。”。</li>
</ol>
<p>大语言模型的“理解”能力，是建立在其从海量训练数据中学习到的复杂模式之上的。清晰、具体、结构化的语言表达，更接近其训练数据中高质量文本所呈现的模式，因此更容易被模型“理解”。提供完整的上下文信息和恰当的示例，则进一步缩小了模型需要匹配和参考的模式范围，使其能够更精确地定位到与当前任务最相关的知识和生成策略。而积极的指令框架和对关键信息的强调，则为模型提供了更强的信号指引。遵循这些基本原则，本质上就是用模型“最熟悉”、“最容易理解”且“最不容易产生歧义”的方式与其进行有效沟通。这不仅仅是告诉模型“做什么”，更是在指导它“如何理解去做什么”，力求将我们的提示词与模型内在的“世界模型”和工作机制相对齐。</p>
<p><strong>建议表格1：提示词核心组成要素及其作用表</strong></p>
<table>
<thead>
<tr>
<th>要素 (Component)</th>
<th>定义 (Definition)</th>
<th>作用与重要性 (Role &amp; Importance)</th>
<th>示例 (Example)</th>
<th>关键相关 Snippets</th>
</tr>
</thead>
<tbody><tr>
<td>角色 (Persona&#x2F;Role)</td>
<td>为LLM设定的特定身份或视角。</td>
<td>影响输出的语气、风格、专业程度；使回答更具针对性。</td>
<td>&quot;扮演一位经验丰富的市场分析师…&quot;</td>
<td></td>
</tr>
<tr>
<td>任务 (Task)</td>
<td>用户要求LLM完成的核心目标或生成的内容类型。</td>
<td>明确LLM需要“做什么”，是prompt的核心驱动力。</td>
<td>&quot;总结以下文章的主要观点。&quot;</td>
<td></td>
</tr>
<tr>
<td>指令 (Instructions)</td>
<td>为完成任务而提供的具体步骤、规则、约束或方法。</td>
<td>细化任务执行方式，提高输出的精确性和可控性。</td>
<td>&quot;请按重要性降序列出，每点不超过20字。&quot;</td>
<td></td>
</tr>
<tr>
<td>上下文 (Context)</td>
<td>完成任务所需的背景信息、参考材料或相关情境。</td>
<td>帮助LLM理解任务环境，消除歧义，聚焦相关信息。</td>
<td>&quot;基于所附的最新季度财报…&quot;</td>
<td></td>
</tr>
<tr>
<td>输入数据 (Input Data)</td>
<td>LLM需要直接处理的具体信息或数据。</td>
<td>作为LLM执行任务的操作对象。</td>
<td>&quot;文本：[粘贴待分析文本]&quot;</td>
<td></td>
</tr>
<tr>
<td>输出格式 (Output Format)</td>
<td>对LLM生成结果的结构、样式、长度等表现形式的要求。</td>
<td>确保输出符合预期，便于后续使用或阅读。</td>
<td>&quot;请以JSON格式返回结果，包含’key’和’value’字段。&quot;</td>
<td></td>
</tr>
<tr>
<td>示例 (Examples&#x2F;Few-shot)</td>
<td>提供一或多个输入&#x2F;输出配对的范例。</td>
<td>通过模仿学习帮助LLM理解任务细节、风格和期望的输出质量。</td>
<td>&quot;Q: 苹果是什么颜色？ A: 红色或绿色。 Q: 天空是什么颜色？ A: &quot;</td>
<td></td>
</tr>
</tbody></table>
<p>此表格系统地梳理了提示词的各个构成要素，阐明了它们各自的定义、在引导模型行为方面所起的作用及重要性，并结合了具体的示例和关键的文献来源。用户通过理解和运用这个表格，能够更清晰地解构现有的提示词，并有针对性地构建新的、包含所有必要信息的高质量提示词。这为用户提供了一个基础性的参照框架，使其在实践中能够有意识地考虑和组合这些要素，以达到更优的提示效果。</p>
<h2 id="三、结构化提示词设计：提升清晰度与可控性"><a href="#三、结构化提示词设计：提升清晰度与可控性" class="headerlink" title="三、结构化提示词设计：提升清晰度与可控性"></a>三、结构化提示词设计：提升清晰度与可控性</h2><h3 id="A-结构化表达的重要性"><a href="#A-结构化表达的重要性" class="headerlink" title="A. 结构化表达的重要性"></a>A. 结构化表达的重要性</h3><p>结构化提示词对于优化大语言模型的输出至关重要。它通过清晰地定义上下文和用户期望，显著减少了指令的模糊性，从而大幅提升了模型响应的相关性和准确性。一个良好结构的提示词，能够帮助AI模型更容易地理解和解析复杂的输入信息。尤其是在处理多步骤或包含多个组成部分（如指令、上下文、待处理数据、输出要求等）的复杂任务时，缺乏明确结构的提示词往往难以引导模型产生令人满意的结果。相反，结构化的提示词通过其内在的组织逻辑，能够引导模型按照特定的、预设的路径来处理信息，这不仅提高了输出的稳定性，也增强了结果的可预测性。<br>从更深层次来看，结构化表达并不仅仅局限于单个提示词内部各组成部分的有序组织，它还体现了一种更宏观的工程思维，即将一个复杂的大任务分解为一系列结构清晰、逻辑相连的子任务序列。这种模块化的处理方式，使得每个子任务的提示词可以设计得更为专注和精确，从而降低了整体任务的认知复杂度和模型出错的概率。</p>
<h3 id="B-有效运用分隔符和格式化"><a href="#B-有效运用分隔符和格式化" class="headerlink" title="B. 有效运用分隔符和格式化"></a>B. 有效运用分隔符和格式化</h3><p>分隔符 (Delimiters)：<br>在提示词中，使用明确的标记符号（如三引号 “””、XML标签 <tag></tag>、###、— 等）来清晰地分隔指令、上下文信息、待处理的输入数据以及对输出格式的要求等不同部分，是一种非常有效的策略。这些分隔符如同文本中的“标点”或“边界”，能够帮助模型准确地区分和识别提示词的各个功能区域。这样做的好处在于，可以有效防止模型将指令本身误认为是待处理的内容，或者将上下文信息与具体问题混淆，从而减少了误解的产生。特别地，当提示词中需要包含用户提供的、内容不可控的文本时（例如，用户输入的待总结文章或待回答问题），使用分隔符将这部分用户输入与提示词的其他指令部分隔离开来，对于防范“提示注入”（Prompt Injection）攻击——即用户输入中可能包含恶意指令试图覆盖或操纵原始提示意图——具有一定的保护作用。<br>例如，一个使用三反引号作为分隔符的提示词可以是：<br>请总结被<code>符号包围的文本的主要观点。 文本：</code>{text_input}&#96;&#96;&#96;</p>
<p>或者，使用XML标签来区分指令和待翻译文本：<br><instruction>请将以下文本翻译成标准法语：</instruction><br><text_to_translate>{user_text}</text_to_translate></p>
<p>格式化输出 (Formatted Output)：<br>明确要求模型以特定的、结构化的格式来生成其输出，例如JSON、Markdown、HTML、项目符号列表、编号列表等，是提升提示词可控性的重要手段。结构化的输出不仅使得信息呈现更为清晰、易于人类阅读和理解，更重要的是，它极大地便利了后续的程序化解析和自动化处理。例如，当要求模型以JSON对象的形式返回包含特定键值对的信息时，应用程序可以直接将模型的输出解析为一个数据结构，并进行后续的逻辑处理或数据存储。<br>一个要求JSON输出的例子：<br>请分析所附文本中的主要实体及其情感倾向。输出一个JSON对象，其中包含一个名为”entities”的数组，每个数组元素是一个对象，包含”name”（实体名称）和”sentiment”（积极&#x2F;消极&#x2F;中性）两个键。</p>
<p>另一个要求列表输出的例子：<br>任务：生成可再生能源的三个主要优点，并以编号列表形式呈现：</p>
<ol>
<li>[优点1的详细描述]</li>
<li>[优点2的详细描述]</li>
<li>[优点3的详细描述]</li>
</ol>
<p>使用项目符号和编号列表 (Bullet Points and Numbered Lists)：<br>当提示词本身包含一系列指令步骤、需要考虑的多个因素，或者希望模型列举多个并列信息点时，使用项目符号（如 -, *）或编号列表（如 1., 2., a., b.）来组织这些内容，可以显著提高提示词的可读性和逻辑清晰度。这种结构化的呈现方式有助于模型准确理解指令之间的顺序关系（对于编号列表）或并列关系（对于项目符号），并据此组织其思考过程和输出内容。<br>例如，一个包含多个步骤指令的提示词：<br>“请按照以下步骤分析提供的文本，并给出最终的综合评估结果。<br>首先，用一句话概括文本的核心主题。<br>其次，将这句概括翻译成英文。<br>然后，列出文本中出现的所有关键人物或组织名称。<br>最后，基于以上分析，对文本的整体论证强度给出一个简短评价。”<br>分隔符和格式化是实现提示词“意图清晰化”和“输出可用化”的两个相辅相成的重要手段。它们巧妙地将自然语言的灵活性与机器处理信息所必需的结构性结合起来。大语言模型在处理冗长且缺乏明确结构的文本时，容易遗漏关键信息或混淆不同部分的意图。分隔符通过在信息流中创建明确的逻辑边界，帮助模型有效地“分块”处理和理解输入，从而降低其认知负荷。而格式化输出的指令，则为模型在“创造”和“组织”其回应内容时，提供了一个清晰的“蓝图”或“模板”。这使得模型的输出不再是完全自由、难以预测的文本流，而是能够符合特定规范、易于下游系统集成的结构化数据或半结构化文本。这些技巧将简单的用户查询转化为一种更接近于微型程序或数据输入表单的交互方式，从而显著增强了与LLM交互的可预测性和输出结果的实用性。</p>
<h3 id="C-复杂任务的分解策略"><a href="#C-复杂任务的分解策略" class="headerlink" title="C. 复杂任务的分解策略"></a>C. 复杂任务的分解策略</h3><p>大语言模型在处理包含多个指令、需要多步推理或涉及大量信息的复杂任务时，其性能可能会下降，出现遗漏、逻辑不连贯或输出质量不均等问题。将复杂任务分解为一系列更小、更简单、更易于管理的子任务，是一种行之有效的应对策略，有助于提高整体的可控性、可调试性和最终输出的准确性。<br>串联提示 (Sequential&#x2F;Chained Prompts)：<br>此策略适用于那些具有明确先后顺序和逻辑依赖关系的复杂流程。它将整个任务拆分为多个连续的子任务，每个子任务对应一个独立的提示词。前一个子任务的输出结果，会作为后一个子任务的输入信息或上下文，以此类推，直至最后一个子任务完成并生成最终的整体结果。这种方法的好处在于，每一步的输出都可以被独立地验证和优化，从而更容易定位和修正问题。例如，在分析客户反馈的场景中，可以将任务分解为：<br>任务1 (提取问题与情感): 第一个提示词指示模型从原始客户反馈文本中提取主要问题点和相关的情感倾向。<br>任务2 (问题分类): 第二个提示词接收任务1的输出（问题点列表和情感），并指示模型将这些问题归类到预设的类别中（如服务可靠性、计费问题、客户支持质量等）。<br>任务3 (生成解决方案): 第三个提示词则基于任务2产出的分类问题，指示模型为每个类别生成详细的、可操作的改进建议，以提升客户满意度。<br>并行子任务与汇总 (Parallel Sub-tasks and Summarization&#x2F;Aggregation)：<br>当一个复杂任务可以被分解为多个相对独立、没有严格执行顺序的子任务时，可以采用此策略。这些子任务的提示词可以被并行处理，待所有子任务完成后，再将它们各自的输出结果进行汇总、整合或进一步分析，以得出最终的结论或答案。金融领域提出的“分层拆解原则”，即将复杂的任务场景及其涉及的繁杂金融数据分层拆解为独立的子任务，正是这种思想的体现，它旨在提高大模型输出的可解释性，并便于后期的优化和管理。例如，一家唱片店希望根据在线音乐流媒体的流行趋势和实体店内的销售数据来决定哪些唱片应该增加库存。这个决策过程可以分解为：<br>任务1a (分析销售数据): 一个提示词指示模型分析店铺的历史销售数据，统计每张唱片的销售数量。<br>任务1b (分析流媒体数据): 另一个提示词（可与任务1a并行执行）指示模型分析在线音乐平台的流媒体数据，统计每张专辑的播放次数或流行度指标。<br>最终汇总提示: 最后一个提示词接收任务1a和1b的输出结果，并指示模型综合考虑销售历史和流媒体热度（可能赋予销售历史更高的权重），推荐一个包含约20张唱片的库存清单。<br>引导模型逐步思考 (Guiding Step-by-Step Thinking &#x2F; Chain of Thought as a Decomposition Strategy)：<br>指示模型在得出最终结论之前，先进行自主的、显式的思考过程，或者明确列出解决问题的步骤，这本身也是一种重要的任务分解形式。通过这种方式，模型被引导将其内部复杂的推理过程分解为一系列更小、更易于管理的思考环节，从而提高其解决复杂问题的能力和输出的逻辑性。例如，在要求模型分析一段文本并给出结果时，可以指示它：“请按照以下步骤进行：1. 用一句话概括文本内容。2. 将概括翻译成英文。3. 列出故事中的人名。”。或者，在要求模型判断一个学生给出的数学解题步骤是否正确时，可以先要求模型自己独立解决该数学问题，然后再将其解法与学生解法进行比较，最后给出评判。<br>任务分解策略的核心价值在于，它有效地应对了大语言模型在处理长程依赖关系、多重约束条件或高度复杂逻辑时可能出现的能力瓶颈。它巧妙地将一个看似“一口难以吞下的大象”的宏大难题，转化为一系列“小口细嚼慢咽”的可行步骤。大语言模型的上下文窗口长度和其一次性准确处理复杂指令的能力都是有限的。过于复杂的单体任务很容易超出这些内在限制，导致在处理过程中发生错误累积或关键信息的遗漏。任务分解通过将大问题转化为小问题，确保了每个子问题都处于模型能够高效处理的能力范围之内。然后，通过串联或并联的方式巧妙地组合这些子任务的解，就能够逐步构建出原复杂任务的完整且高质量的解决方案。因此，对于复杂的应用场景，有效的提示工程往往不仅仅是设计单个出色的提示词，更涉及到设计整个提示词的“工作流程”（workflows）或“处理管道”（pipelines）。在这一点上，提示工程开始展现出与传统软件工程在系统设计层面相似的复杂性和重要性。</p>
<h2 id="四、核心提示词工程技术详解"><a href="#四、核心提示词工程技术详解" class="headerlink" title="四、核心提示词工程技术详解"></a>四、核心提示词工程技术详解</h2><h3 id="A-基础技巧：零样本（Zero-shot）与少样本（Few-shot）提示"><a href="#A-基础技巧：零样本（Zero-shot）与少样本（Few-shot）提示" class="headerlink" title="A. 基础技巧：零样本（Zero-shot）与少样本（Few-shot）提示"></a>A. 基础技巧：零样本（Zero-shot）与少样本（Few-shot）提示</h3><p>零样本提示 (Zero-shot Prompting)：<br>零样本提示是指在不向大语言模型提供任何具体任务完成范例的情况下，直接通过指令或问题来要求模型执行任务。模型完全依赖其在海量数据上预训练过程中学习到的知识和泛化能力来理解指令并生成回应。这种方法适用于模型已经具备较强预训练能力、任务本身相对简单直接、或者期望模型发挥其创造性的场景。例如，常见的零样本提示应用包括简单的文本分类（如判断文本情感是积极、消极还是中性）、进行常识性问答（如“法国的首都是哪里？”）或生成简短的描述性文本。一个零样本提示的例子是：“请将以下文本分类为积极、消极或中性。”，或者“请从下面的文本中提取关键词。”。<br>零样本提示的主要优点在于其简单快捷，用户无需花费额外精力准备和构建示例。然而，其局限性也十分明显：对于那些模型未在预训练数据中充分学习过的、较为复杂或不常见的任务，零样本提示的效果往往不尽如人意，可能导致输出不准确或不符合预期。因此，它通常被用作与模型交互的起点，或作为快速测试模型对某一基本任务理解程度的方法。<br>少样本提示 (Few-shot Prompting)：<br>少样本提示则是在提示词中包含少量（通常是一到五个）与当前任务相关的输入和期望输出的配对示例，以此来引导和“教会”模型如何完成特定任务的模式。通过这种“情境学习”（in-context learning）的方式，少样本提示能够显著提升模型在特定任务上的表现，尤其是在需要模型遵循特定输出格式、特定写作风格，或者处理模型在预训练阶段未明确学习过的细分任务时。所提供示例的质量、格式的一致性以及内容的多样性，都会对最终的输出效果产生重要影响。例如，在一个情感分类任务中，可以提供如下的少样本示例（其中示例标签甚至是随机分配的，但格式保持一致，模型依然能学习到任务模式）：“文本：这部电影太棒了！ &#x2F;&#x2F; 情感：消极（随机标签示例） \n 文本：这个产品很糟糕。 &#x2F;&#x2F; 情感：积极 \n 文本：哇，那场演出真是太酷了！ &#x2F;&#x2F; 情感：积极 \n 文本：多么可怕的节目！ &#x2F;&#x2F; 情感：” 模型在看到这样的示例后，即使标签是随机的，也能更好地理解任务是进行情感判断，并尝试给出“消极”的输出。另一个例子是日期格式转换，可以给出：“将日期 03&#x2F;15&#x2F;2024 转换为 YYYY-MM-DD 格式：2024-03-15。那么，将日期 07&#x2F;04&#x2F;2023 转换为 YYYY-MM-DD 格式是：”。<br>少样本提示的优点在于它能够非常有效地引导模型，提高输出的准确性和质量，并且这一切都无需对模型本身进行重新的训练或微调。然而，它也存在一些局限性，例如精心选择和构建高质量的示例本身就需要一定的技巧和工作量；同时，由于模型处理的上下文窗口长度有限，能够包含的示例数量也受到限制。<br>零样本和少样本提示代表了与大语言模型交互的两种基本模式。零样本提示主要依赖模型在预训练阶段获得的广泛泛化能力，而少样本提示则巧妙地利用了模型强大的情境学习能力，使其能够根据当前提示中提供的少量具体示例快速适应新任务。在实践中，选择哪种方法通常取决于任务的复杂程度、对输出质量的精确要求，以及是否有高质量的示例可供使用。当模型面对一个全新的、特定的或有细微差别的任务时，其预训练知识可能不足以直接产生精确的输出。此时，少样本提示通过提供具体的“锚点”（即示例），帮助模型在其庞大的内部知识表示空间中，迅速定位到与当前任务最相关的模式和处理方式。模型通过观察和比较示例中的输入与期望输出之间的关系，能够快速“领悟”任务的内在规则和期望的格式。从这个意义上说，少样本提示是一种强大的、无需改变模型权重即可在“运行时”对LLM进行“编程”或“微调”的方法，充分展现了模型的元学习（meta-learning）潜能。而这些“少数样本”的质量，在某种程度上扮演了该特定交互场景下的“即时训练数据”的角色。</p>
<h3 id="B-高级推理技术"><a href="#B-高级推理技术" class="headerlink" title="B. 高级推理技术"></a>B. 高级推理技术</h3><p>为了应对更复杂的任务，特别是那些需要多步逻辑、规划或与外部世界交互的任务，研究者们开发了一系列高级提示工程技术。这些技术的核心在于更精细地引导模型的“思考”过程，或者赋予模型超越自身知识库的能力。<br>思维链 (Chain-of-Thought, CoT) Prompting：<br>思维链提示是一种旨在激发和引导大语言模型进行显式、逐步推理的技术。它通过在提示中加入特定的引导语（如“让我们一步一步地思考”）或者提供包含详细中间推理步骤的少样本示例，来促使模型在给出最终答案之前，先生成一系列连贯的、构成完整思考过程的中间步骤。CoT技术已被证明能够显著提升LLM在处理需要多步逻辑推导的任务（例如数学应用题、常识推理、符号操作等）时的表现。它通过将复杂的思考过程分解为一系列更小、更易于管理的部分，使得模型能够更可靠地处理这些任务。<br>思维链提示主要有以下几种形式：<br>零样本CoT (Zero-shot CoT)： 这是最简单的一种CoT实现方式，只需在用户提出的问题或任务指令之后，追加一句类似“让我们一步一步地思考”或“Let’s think step by step”的引导语即可。例如，对于问题“我去市场买了10个苹果，给了邻居2个，修理工2个，然后我又去买了5个苹果，吃掉了1个。我还剩多少苹果？”，可以在其后加上“让我们一步一步地思考。”来引导模型给出详细的计算步骤。<br>少样本CoT (Few-shot CoT)： 这种方式则是在提示中提供一个或多个完整的示例，每个示例都清晰地展示了从问题到中间推理步骤再到最终答案的完整思考链条。例如，在解决数学问题时，可以给出几个类似问题的完整解题过程作为示范。<br>自动CoT (Auto-CoT)： 鉴于手动构建高质量的少样本CoT示例可能非常耗时，自动CoT技术应运而生。它通过自动化的方法来构建包含推理链的示例，例如通过对一系列问题进行聚类，然后为每个聚类选择一个代表性问题，并利用零样本CoT的方式为其生成推理链，以此作为后续任务的少样本示例。 CoT的主要优点在于能够显著提高模型在复杂推理任务上的准确性，并且由于其显式地展示了推理过程，也增强了模型输出的可解释性和透明度。然而，CoT技术通常在参数量足够大的模型上才能展现出明显的效果，且手动构建高质量的少样本CoT示例仍然是一项具有挑战性的工作。<br>思维树 (Tree of Thoughts, ToT) Prompting：<br>思维树提示技术允许大语言模型在解决问题的过程中，不再局限于单一的线性推理路径，而是能够同时探索多个不同的推理分支（即“思想”），并在每个步骤对这些分支的有效性、前景和价值进行评估，甚至在发现某一分支可能走向死胡同时进行回溯，转而探索其他更有希望的路径。ToT通过模拟人类在面对复杂问题时所进行的试错、多角度思考和战略规划过程，显著增强了模型在那些需要深度规划、广泛探索和战略前瞻的复杂任务（例如数学策略游戏“24点游戏”、开放式创意写作等）中的表现。它有效地克服了传统思维链（CoT）主要依赖线性推理的局限性。<br>ToT的核心组件包括：<br>提议生成器 (Propose prompts&#x2F;Thought Generator)： 负责在当前思考节点上，生成多个可能的下一步解决方案或思考方向。<br>价值评估器 (Value prompts&#x2F;State Evaluator)： 负责评估提议生成器产生的各个“思想”或“状态”的价值，判断它们是否有助于最终解决问题，并指导模型选择最有希望的路径继续深入。<br>搜索算法 (Search Algorithm)： 如广度优先搜索（BFS）或深度优先搜索（DFS），用于系统性地探索由“思想”构成的树状结构。 例如，在“24点游戏”中，模型每一步可能会生成多个不同的算式组合作为候选“思想”，然后评估哪个算式最有可能导向最终结果。在创意写作任务中，模型可能在某个情节节点生成多个不同的故事发展后续，然后评估哪个发展最具吸引力或最符合主题。 ToT的主要优点在于能够显著提升模型解决复杂问题的能力，并产出更准确、更连贯的解决方案。然而，其实现也相对复杂，且在计算资源消耗上可能较大。<br>ReAct (Reasoning and Acting) Prompting：<br>ReAct框架巧妙地将大语言模型的“推理”（Reasoning）能力与“行动”（Acting）能力相结合，使模型能够生成详尽的推理轨迹来创建、维护和动态调整其行动计划，并且能够通过与外部工具（如搜索引擎、计算器、API接口、特定知识库等）进行交互来获取额外信息或执行特定操作，然后根据从外部环境中观察到的结果来更新其内部的推理状态和后续计划。ReAct的核心思想在于使LLM能够处理那些需要超出其自身静态知识库的、实时的或特定领域信息的复杂任务，从而有效克服LLM固有知识的局限性（如知识截止日期、缺乏特定领域深度知识等），并显著提高其在事实密集型任务中的准确性和任务完成能力。<br>ReAct的工作流程通常遵循一个“思考（Thought）-&gt; 行动（Action）-&gt; 观察（Observation）”的循环迭代过程：<br>Thought: 模型首先分析当前任务和已有信息，生成一个关于下一步应该做什么的内部思考或计划。<br>Action: 基于这个思考，模型决定采取一个具体的行动，这个行动可能涉及查询外部知识库、调用某个API、执行一段代码，或者在模拟环境中进行某种操作。<br>Observation: 模型从执行行动后获得一个观察结果，这个结果可能是一个搜索结果、API的返回值、代码的运行输出，或者是环境状态的变化。模型将这个观察结果整合到其当前的理解中，并开始下一轮的“Thought”过程。 ReAct框架在多种任务中都展现了其优越性，例如知识密集型问答（如HotPotQA，需要综合多个文档信息才能回答的问题）、事实核查（如Fever任务，需要验证陈述的真实性）、以及与交互式环境进行互动的决策任务（如文本冒险游戏ALFWorld，模拟在线购物环境WebShop）。 ReAct的主要优点包括：能够显著提高对事实性问题的回答准确率，有效减少模型产生“幻觉”的概率；增强模型处理现实世界中复杂、动态任务的能力；通过显式展示思考和行动过程，提高了人机交互的可解释性和用户对模型决策的信任度。然而，ReAct的性能在很大程度上也依赖于其能够调用的外部工具的质量和返回信息的准确性；同时，其结构化的思考-行动框架有时也可能限制了模型在推理过程中的灵活性。<br>CoT、ToT和ReAct这些高级提示技术，代表了提示工程在模拟和增强人类复杂认知过程方面所做出的重要努力。它们已经超越了简单的指令给予，而是试图为大语言模型构建一个更精细、更强大的“思考框架”或“行动策略”。<br>对于思维链（CoT）而言，其核心价值在于，复杂问题往往可以被分解为一系列相对简单的中间步骤。大语言模型在直接尝试解决整个复杂问题时，很容易在某个中间环节出错或跳过关键的逻辑节点。CoT通过明确引导LLM生成这些中间步骤，有效地降低了模型在每一步推理上的认知负荷，使得模型能够更稳定、更准确地完成整个推理过程。这不仅提升了结果的准确性，更重要的是，它通过“展示其工作过程”，为我们提供了洞察其内部“思考”的窗口，使得模型的决策过程更加透明，也更易于调试和建立信任。<br>而思维树（ToT）则在此基础上更进一步。许多复杂问题并非只有唯一的线性解决方案路径，往往需要探索和比较多种不同的可能性。CoT的线性推理模式在这种探索性任务中显得力不从心。ToT通过允许LLM在每个决策节点生成和评估多个并行的“思想分支”，实现了对解决方案空间的更全面搜索。其内置的自我评估和回溯机制，使得LLM能够像人类一样动态调整其探索策略，避免在没有前景的路径上浪费过多资源，从而更好地模拟了人类的创造性思维和战略规划能力。<br>ReAct框架则赋予了LLM突破自身知识边界、与真实世界互动的能力。LLM的知识库是基于其训练数据构建的，因此是静态的，并且可能存在不完整或过时的情况。许多现实世界的任务，恰恰需要访问动态变化的外部环境或获取最新的信息。ReAct通过赋予LLM“行动”的能力——即调用外部工具或API——使其能够主动获取和整合这些外部信息，从而弥补自身知识的不足。推理过程指导着行动的选择，而行动的结果（观察）又反过来为后续的推理提供新的依据，形成了一个有效的感知-思考-行动的闭环。这使得LLM从一个被动的知识存储库，转变为一个能够在动态环境中主动进行信息收集和任务执行的智能代理。</p>
<h3 id="C-自我校正与迭代优化技术"><a href="#C-自我校正与迭代优化技术" class="headerlink" title="C. 自我校正与迭代优化技术"></a>C. 自我校正与迭代优化技术</h3><p>在高级提示工程中，除了引导模型进行更复杂的推理和与外部工具交互外，还有一类重要的技术旨在提升模型输出的质量和可靠性，即通过机制让模型能够对其自身的生成结果进行评估和修正。这体现了从“一次性生成”向“迭代优化”和“自我提升”的转变，试图在LLM内部或通过外部框架引入一种元认知（meta-cognition）的能力。<br>自我一致性 (Self-Consistency)：<br>自我一致性是一种旨在提高思维链（CoT）等推理技术稳定性和准确性的方法。其核心思想是，针对同一个问题，通过多次、多样化的思维链采样（例如，使用不同的少样本示例、调整模型的温度参数以增加输出的随机性，或者采用不同的解码策略），生成多个不同的推理路径和相应的答案。然后，通过一种“多数投票”的机制，选择在这些不同推理路径中出现频率最高的那个答案作为最终的、最可靠的输出。这种方法旨在取代在标准CoT提示中通常采用的简单贪婪解码策略（即每一步都选择概率最高的词元）。<br>例如，在解决一个数学应用题时，模型可能会被引导生成3到5条不同的解题思路和计算过程，每条路径都可能得到一个答案。如果在这多个答案中，“答案A”出现了3次，“答案B”出现了1次，“答案C”出现了1次，那么根据自我一致性原则，最终会选择“答案A”作为输出。<br>自我一致性的主要优点在于它无需额外的人工标注或对模型本身进行微调，可以直接应用于预训练好的大语言模型。它通过利用模型自身生成的多样性来提高结果的鲁棒性，尤其在算术推理、常识推理等任务上，当模型规模较大时，其性能提升效果更为显著。大语言模型的生成过程本身具有一定的随机性，即使是使用了思维链技术，单一的推理路径也可能因为解码策略的选择或模型内部状态的微小波动而导向错误的结论。自我一致性通过采样多个独立的推理路径，实际上是在解决方案空间中探索了不同的区域。如果多个不同的、看似合理的推理路径最终都指向同一个答案，那么这个答案的可靠性自然就比单一路径得出的答案要高。这在某种程度上借鉴了“群体智慧”的原理，只不过这里的“群体”是由模型自身的多次、多样化推理过程构成的，从而使其对个别推理错误更具鲁棒性。<br>反思 (Reflection &#x2F; Self-Reflection &#x2F; Self-Critique)：<br>反思或自我批判技术旨在引导大语言模型对其已经生成的初步输出、采取的行动、依赖的知识或其内部的推理过程进行审视、评估和批判，并在此基础上进行有针对性的改进和修正。这种方法模仿了人类通过反思和从错误中学习来提升自身能力的过程，期望帮助LLM识别其输出中可能存在的错误、不一致、不完整或不恰当之处，减少误报和漏报，并逐步完善答案，最终提高输出的整体准确性、可靠性和质量。<br>反思技术有多种具体的实现形式，例如：<br>自我校准 (Self-Calibration): 促使LLM评估其自身回答的置信度或确定性，帮助其识别可能存在错误或把握不足的地方。<br>自我完善 (Self-Refine): LLM在生成初始答案后，通过迭代的方式，根据自我评估或外部反馈（也可以是LLM自身生成的反馈）逐步改进其答案。<br>逆向思维链 (Reversing Chain-of-Thought, RCoT): 一种检测和修正幻觉的方法。首先让模型解决一个问题，然后要求模型基于其给出的解决方案反向构造一个新的、能够引出该解决方案的问题。通过比较原始问题和新构造的问题之间的一致性，来发现潜在的逻辑断裂或不合理假设。<br>自我验证 (Self-Verification): 模型首先使用CoT生成多个候选解决方案。然后，通过掩盖原始问题中的部分信息，并要求模型基于剩余问题和其生成的解决方案来预测被掩盖的信息，以此来验证每个候选方案的合理性。<br>验证链 (Chain-of-Verification, CoVe): 与CoT不同，CoVe在模型给出初步回答后，引导模型生成一系列用于验证该回答准确性和完整性的问题，然后模型再回答这些自生成的问题，并据此来修正和完善其最初的回答。<br>累积推理 (Cumulative Reasoning, CR): 将复杂问题的解决过程分解为多个步骤，每个步骤的输出都由LLM进行评估，以决定是接受该步骤的结果并继续，还是拒绝并进行修正。 一些框架和工具也集成了反思机制，如LangChain的Reflection Agents和微软的AutoGen中的多智能体反思架构。例如，在一个写作任务中，可以设计一个“写作助手”LLM负责生成初稿，然后由另一个“反思助手”LLM（或同一个LLM扮演不同角色）对初稿进行批判性评估，并提出具体的改进建议，写作助手再根据这些建议进行修改。 反思技术的主要优点在于能够显著提高模型输出的质量、准确性和任务的成功率，并使LLM的行为模式更接近于人类深思熟虑的“系统2思维”。人类的学习和进步在很大程度上依赖于反思和批判性思维。LLM的初始输出，即使经过了CoT等技术的引导，也仍然可能存在各种缺陷，例如事实错误、逻辑不通、表达不清、风格不符或遗漏关键信息等。通过明确指示LLM（或者由另一个专门的LLM扮演批判者角色）对其自身的输出进行严格的、有据可依的批判性评估，就可以有效地识别出这些潜在的缺陷。随后，基于这些具体的批判意见，LLM可以被引导生成一个或多个改进的版本。这个“生成-评估-改进”的迭代过程可以持续进行，直到输出质量达到预设的满意标准。这实际上是在LLM的生成流程中引入了一个内部或外部的反馈回路，使其能够在单次交互或多次交互中从自身的“错误”或不足之处学习，从而实现持续的自我优化和能力提升。这无疑是朝着构建更具自主学习能力的智能代理迈出的重要一步。</p>
<p><strong>建议表格2：高级提示词技术对比表</strong></p>
<table>
<thead>
<tr>
<th>技术名称 (Technique)</th>
<th>定义 (Definition)</th>
<th>核心思想 (Core Idea)</th>
<th>适用场景 (Use Cases)</th>
<th>优点 (Pros)</th>
<th>缺点 (Cons)</th>
<th>关键相关 Snippets</th>
</tr>
</thead>
<tbody><tr>
<td>思维链 (Chain-of-Thought, CoT)</td>
<td>引导LLM生成中间推理步骤。</td>
<td>分解复杂问题，逐步推理。</td>
<td>数学题、逻辑推理、常识问答。</td>
<td>提高准确性、可解释性。</td>
<td>主要对大模型有效，示例构建耗时。</td>
<td>-</td>
</tr>
<tr>
<td>思维树 (Tree of Thoughts, ToT)</td>
<td>LLM探索和评估多个推理路径。</td>
<td>模拟人类探索式、战略性思考。</td>
<td>复杂规划（24点游戏）、创意写作。</td>
<td>解决更复杂问题，方案更优。</td>
<td>实现复杂，资源消耗大。</td>
<td>-</td>
</tr>
<tr>
<td>ReAct (Reasoning and Acting)</td>
<td>结合推理与行动，与外部工具交互。</td>
<td>弥补LLM静态知识，处理动态信息。</td>
<td>需外部知识的问答、事实核查、交互式任务。</td>
<td>提高事实准确性，处理现实任务。</td>
<td>依赖外部工具质量，可能降低推理灵活性。</td>
<td>-</td>
</tr>
<tr>
<td>自我一致性 (Self-Consistency)</td>
<td>多次采样不同推理路径，选择最一致答案。</td>
<td>通过多数投票提高答案鲁棒性。</td>
<td>算术、常识推理。</td>
<td>提高CoT性能，无需额外训练。</td>
<td>增加计算成本。</td>
<td>-</td>
</tr>
<tr>
<td>反思 (Reflection &#x2F; Self-Critique)</td>
<td>LLM评估和改进自身输出。</td>
<td>模拟人类反思学习，迭代优化。</td>
<td>内容生成、复杂问答、代码生成。</td>
<td>提高输出质量和成功率，增强鲁棒性。</td>
<td>增加计算成本和延迟。</td>
<td>-</td>
</tr>
</tbody></table>
<p>此表格为用户在面对不同类型的复杂任务时，提供了一个关于如何选择和应用高级提示技术的决策指南。它清晰地对比了思维链（CoT）、思维树（ToT）、ReAct、自我一致性以及反思&#x2F;自我批判这五种主流高级提示技术的定义、核心思想、典型适用场景、主要优势和潜在不足，并指出了相关的关键文献来源。例如，用户可以从中了解到，如果任务需要严格的逻辑逐步推演，CoT可能是合适的起点；如果任务涉及探索多种可能性或需要创造性解决方案，ToT则更具优势；如果任务强依赖外部实时信息或特定工具的功能，ReAct框架将是首选；而当追求在已有推理技术基础上的更高准确性和鲁棒性时，可以考虑结合自我一致性或反思机制。通过这样的对比，用户能够根据自己任务的具体特点（例如，是否需要与外部环境交互、问题是否具有唯一确定答案、是否需要探索多种解决方案路径、对可解释性的要求程度等）来做出更明智的技术选型，从而更有效地利用这些复杂但功能强大的提示工程工具。</p>
<h2 id="五、提示词的迭代开发与效果评估"><a href="#五、提示词的迭代开发与效果评估" class="headerlink" title="五、提示词的迭代开发与效果评估"></a>五、提示词的迭代开发与效果评估</h2><h3 id="A-迭代优化流程：从初步设计到持续改进"><a href="#A-迭代优化流程：从初步设计到持续改进" class="headerlink" title="A. 迭代优化流程：从初步设计到持续改进"></a>A. 迭代优化流程：从初步设计到持续改进</h3><p>编写高质量的提示词并非一蹴而就，它是一个持续迭代、不断试错和优化的过程，很少能够一次性就达到完美的效果。成功的关键并不在于试图一次性构思出“完美”的提示词，而在于掌握并遵循一套行之有效的迭代开发流程。这个流程通常包含以下几个核心步骤：<br>初步设计 (Initial Prompt Design)：<br>首先，基于对任务需求的深刻理解，并结合前述关于高质量提示词核心要素（角色、任务、指令、上下文、输入数据、输出格式、示例）和基本原则（清晰性、具体性、完整性等）的知识，构建一个初始版本的提示词。<br>测试与输出评估 (Test &amp; Assess Output)：<br>将构建好的初始提示词输入到目标大语言模型中，获取其生成的输出结果。然后，需要从多个维度对输出进行仔细评估，包括但不限于：准确性（信息是否正确无误）、相关性（输出是否紧扣主题，回答了问题）、格式（是否符合预设的结构要求）、完整性（是否包含了所有要求的信息）、流畅性（语言表达是否自然通顺）等。<br>分析与反馈 (Analyze &amp; Feedback)：<br>将模型的实际输出与期望的理想输出进行对比，找出两者之间的差距。深入分析造成这些差距的可能原因，例如，是否原始提示词中的指令不够清晰明确？是否缺乏必要的上下文信息？提供的示例是否恰当且具有代表性？模型是否对某些词语或表达产生了误解？。<br>调整与精炼 (Adjust &amp; Refine Prompt)：<br>根据上一步的分析结果，有针对性地对提示词进行修改和完善。这可能包括：增加或修改约束条件（如字数限制、风格要求），提供更优质或更多样化的示例，澄清可能引起歧义的术语，调整提示词的整体结构或各个组成部分的顺序，或者尝试使用更精确的措辞等。<br>重复测试 (Retest &amp; Repeat)：<br>将修改后的提示词再次输入模型进行测试，并对新的输出结果进行评估。比较新旧两个版本提示词所产生的输出之间的差异，判断改进是否有效。同时，系统地记录每次迭代所做的变更及其效果，持续收集来自用户或其他评估者的反馈。这个“测试-评估-分析-调整”的循环过程需要不断重复，直至提示词能够稳定地引导模型产生令人满意的、高质量的输出为止。<br>在实践中，可以利用一些工具来辅助提示词的迭代优化过程。例如，对提示词进行版本控制，可以方便地追踪不同版本的提示词及其效果，也便于在必要时回滚到先前的有效版本。一些平台（如Vertex AI Prompt Optimizer 和 Latitude）提供了A&#x2F;B测试、协作编辑、反馈共享等功能，能够帮助团队更高效地进行提示词的迭代开发和管理。对于一些复杂的应用场景，可能还需要在包含多个不同输入样本的数据集上进行提示词的迭代开发和综合评估，以确保其在各种情况下的鲁棒性。<br>这种迭代优化的方法论，实际上是将科学实验的思想应用于提示工程领域。它正视了大语言模型行为的内在复杂性和一定程度的不可预测性，并通过系统性的、有目的的试错和调整，逐步逼近能够产生最优输出的提示词设计。大语言模型的响应受到提示词中众多细微因素的复杂影响，因此预先一次性设计出“完美”的提示词几乎是不可能的。通过观察模型对某一提示词的实际输出，并将其与我们的期望进行细致比较，我们就能识别出当前提示词设计中存在的不足之处。然后，有针对性地对提示词进行修改，并再次观察模型的输出，就形成了一个有效的反馈与校正循环。这个循环允许我们逐步地、有依据地改进提示词，直到它能够稳定地引导模型产生符合要求的高质量输出。因此，提示工程不仅仅是关于如何从零开始编写好的提示词，更重要的是培养和掌握强大的调试与精炼技能。诊断出一个提示词为何未能按预期工作，并知道如何有效地修正它，是提示工程师的核心竞争力之一。</p>
<h3 id="B-评估提示词有效性的方法与指标"><a href="#B-评估提示词有效性的方法与指标" class="headerlink" title="B. 评估提示词有效性的方法与指标"></a>B. 评估提示词有效性的方法与指标</h3><p>为了客观地评价一个提示词的优劣，并指导其迭代优化方向，需要一套系统化的评估方法和明确的衡量指标。<br>人工评估 (Human Evaluation)：<br>这是评估模型输出质量，尤其是涉及主观判断、细微语义差别或创造性内容时，最为可靠的方法之一。由经验丰富的人类评估员根据预先设定的标准（例如，答案的准确性、相关性、流畅性、逻辑性、信息量、是否遵循指令、是否有害性等）对模型生成的输出进行打分、排序或比较。尽管人工评估成本较高、耗时较长，且可能引入评估者主观偏差，但在理解复杂语境、判断 nuanced 差异方面仍具有不可替代的优势。常见的人工评估方法包括：直接对输出质量进行李克特量表评分，对两个或多个不同提示词产生的输出进行偏好排序（A&#x2F;B&#x2F;n 测试），或者将模型输出与一个“黄金标准”参考答案进行对比打分。<br>自动化评估指标 (Automated Metrics)：<br>为了提高评估效率和可扩展性，学术界和工业界开发了多种自动化评估指标。这些指标可以大致分为基于精确匹配的、基于词汇重叠度的、基于语义相似度的以及其他特定维度的指标。<br>基于精确匹配 (Exact Match, EM)： 要求模型输出的答案与预设的参考答案完全一致。这种方法简单直接，但主要适用于答案唯一且形式固定的任务，如封闭式问答或特定格式的数据提取。<br>基于词汇重叠度的度量：<br>BLEU (Bilingual Evaluation Understudy)： 最初为机器翻译设计，通过计算模型生成文本与一个或多个参考文本之间n-gram（连续的n个词）的重叠度来评估质量。BLEU得分越高，通常认为输出与参考文本越相似。<br>ROUGE (Recall-Oriented Understudy for Gisting Evaluation)： 主要用于文本摘要任务的评估，它关注模型生成的摘要在多大程度上召回了参考摘要中的重要信息点（同样基于n-gram、词序列等的重叠）。<br>METEOR (Metric for Evaluation of Translation with Explicit ORdering)： 也是一种用于翻译评估的指标，它在BLEU的基础上进行了改进，考虑了同义词、词干还原以及词序对齐等因素，通常认为其与人类判断的相关性比BLEU更高。<br>语义相似度度量： 这类方法通常利用词嵌入（word embeddings）或句子嵌入（sentence embeddings）技术，将模型输出和参考答案（或用户查询）转换为向量表示，然后通过计算这些向量之间的余弦相似度或其他距离度量来评估它们在语义层面上的接近程度。得分越高，表示语义越相关。<br>分类与信息提取任务常用指标： 对于文本分类、命名实体识别等任务，可以使用标准的机器学习评估指标，如准确率（Accuracy）、精确率（Precision）、召回率（Recall）和F1分数（F1-Score）。<br>效率与成本相关指标： 包括模型响应的延迟时间（Latency）、处理每个提示词所消耗的计算资源或Token数量，以及由此产生的经济成本。<br>其他特定维度指标：<br>Perplexity (困惑度)： 衡量语言模型对其生成文本的流畅性和可预测性的指标，通常困惑度越低，表示模型对其生成的序列越有信心，文本质量也可能越高。<br>Hallucination Detection (幻觉检测)： 评估模型输出中是否包含与事实不符或无中生有的“幻觉”信息。<br>Toxicity Detection (毒性内容检测)： 评估模型输出中是否包含不当言论、偏见、歧视或其他有害内容。<br>Coherence (连贯性) 和 Consistency (一致性)： 评估模型输出的文本在逻辑上是否连贯，以及在风格、观点等方面是否保持一致。 自动化指标的主要优势在于其可扩展性强、评估效率高，但它们往往只能从特定方面（如词汇重叠、语义相似的某个角度）衡量输出质量，可能无法完全捕捉人类对语言质量的细微感知和整体判断。<br>A&#x2F;B 测试 (A&#x2F;B Testing)：<br>A&#x2F;B测试是一种在真实用户场景或高度模拟的测试环境中，比较两个或多个不同提示词版本（版本A、版本B等）实际表现的有效方法。通过将用户或测试流量随机分配给不同的提示词版本，并追踪预先设定的关键性能指标（KPIs）——例如用户点击率、任务完成率、用户满意度评分、转化率，或者更底层的如响应延迟、Token使用量、由LLM辅助评估的质量分数等——来确定哪个版本的提示词能够带来更优的整体效果。A&#x2F;B测试尤其适用于那些有明确业务目标或用户交互的应用场景，因为它能够直接衡量提示词变更对实际产出的影响。实施A&#x2F;B测试时，需要精心设计实验，确保样本量足够大以获得统计显著的结果，并使用恰当的统计方法（如t检验、方差分析ANOVA等）来分析和解读测试数据。<br>LLM辅助评估 (LLM-assisted Evaluation &#x2F; LLM-as-a-Judge)：<br>这是一种新兴且日益受到关注的评估方法，它利用另一个（通常是更强大、更先进，或者经过专门微调以执行评估任务的）大语言模型来评估目标LLM在特定提示词下生成的输出质量。例如，可以设计一个“评估者LLM”，让它根据一系列预设的评估维度（如答案的帮助性、真实性、无害性、遵循指令的程度等）对目标LLM的输出进行打分或提供定性评价。G-Eval就是此类方法的一个例子，它强调对语义含义和上下文相关性的评估。LLM辅助评估的优势在于其可扩展性介于纯人工评估和纯自动化指标之间，它既能比传统自动化指标评估更细致、更接近人类判断的质量维度（如创造性、逻辑深度、风格契合度等），又能比纯人工评估更高效、成本更低。<br>提示词的“好”与“坏”最终体现在其引导LLM所产生的输出是否能够精准、高效地满足用户的核心需求。用户的需求往往是多维度、多层次的，可能同时涉及到对信息准确性的要求、对内容相关性的期望、对表达流畅性的偏好、对获取效率的关注，乃至对交互安全性的考量等。因此，对提示词有效性的评估也必然是一个多维度的问题，不存在单一的、普适的“万能指标”。不同的评估方法和指标各有其侧重点和适用范围：例如，BLEU和ROUGE等基于词汇重叠的指标更侧重于衡量内容层面的相似性，适合于翻译和摘要等有明确参考答案的任务；人工评估则能够捕捉到自动化指标难以衡量的细微语义差别和主观感受；A&#x2F;B测试关注的是提示词在真实应用环境下的实际业务效果；而LLM辅助评估则试图在评估的深度、广度和效率之间取得一种新的平衡。因此，在实践中，全面而客观地评价一个提示词的有效性，通常需要根据具体的任务特性和应用场景，审慎地选择并组合运用多种评估手段。评估体系正在从依赖单一、简单的指标和大量人工投入，向着更全面、更自动化，并越来越多地由AI自身辅助的智能化方向发展。这使得提示工程的迭代优化过程能够更加科学、高效和可持续。</p>
<h2 id="六、常见提示词编写误区与改进策略"><a href="#六、常见提示词编写误区与改进策略" class="headerlink" title="六、常见提示词编写误区与改进策略"></a>六、常见提示词编写误区与改进策略</h2><h3 id="A-识别低效提示词：常见问题剖析"><a href="#A-识别低效提示词：常见问题剖析" class="headerlink" title="A. 识别低效提示词：常见问题剖析"></a>A. 识别低效提示词：常见问题剖析</h3><p>在与大语言模型交互的过程中，即使用户具备一定的经验，也可能不经意间编写出低效的提示词，从而导致模型输出不尽如人意。识别这些常见误区的特征，是提升提示词质量的第一步。<br>模糊与含糊不清 (Ambiguity and Vagueness)：<br>这是最常见的误区之一。当提示词中使用的词语、短语或指令本身存在多种可能的解释，或者未能清晰地表达用户的确切意图时，模型就难以准确把握需求，其输出结果很可能偏离主题、过于宽泛，甚至产生误导性信息。例如，一个模糊的提示如“给我讲讲气候变化”，模型可能会从成因、影响、历史、未来趋势等多个角度进行阐述，但用户可能只关心其中某一个具体方面。一个更有效的提问方式是：“请用不超过200字的篇幅，解释自1950年以来，人为活动导致气候变化的主要原因及其对全球农业产生的显著影响” 。<br>缺乏上下文 (Missing Context)：<br>大语言模型虽然拥有海量的知识，但它们并非全知全能，尤其缺乏对特定、即时或私有情境的理解。如果提示词未能提供足够的、与任务相关的背景信息，模型就如同在真空中作业，难以做出准确的判断和生成符合特定需求的输出。例如，仅仅说“请为我推荐一篇关于市场细分的文章”，模型给出的可能是非常通用的内容。但如果补充上下文：“我是一名正在为初次接触客户研究的团队成员寻找学习资料，请为我推荐一篇适合初学者的、关于市场细分基础概念和实用方法的入门文章”，那么模型的推荐就会更有针对性。<br>过度复杂或指令过多 (Over-complexity &#x2F; Too Many Instructions)：<br>试图在单个提示词中塞入过多的不相关指令、相互冲突的要求，或者构建过于复杂的逻辑结构，都可能使模型感到困惑，难以有效处理所有信息，甚至可能导致其忽略部分指令或产生逻辑混乱的输出。此时，更佳的策略是将复杂任务分解为一系列更小、更专注的子提示，逐步引导模型完成。<br>过于简单或信息不足 (Overly Simplistic &#x2F; Insufficient Information)：<br>与过度复杂相对的是，提示词如果过于简单、概括，未能提供足够的细节来充分引导模型，也可能导致模型只能给出非常通用、宽泛甚至空洞的回答，无法满足用户的具体需求。例如，简单的“写一篇关于市场的文章”几乎无法让模型了解用户到底想了解市场的哪个方面。<br>忽视目标受众和目的 (Ignoring Audience and Purpose)：<br>在编写提示词时，如果没有明确指出生成内容的目标受众是谁，以及期望达成的具体目的是什么，那么模型生成的文本在风格、语言复杂度、信息深度等方面很可能与实际需求不匹配。例如，为专业人士撰写的技术报告与为普通大众撰写的科普文章，其提示词设计应有显著差异。<br>缺乏结构 (Lack of Structure)：<br>如果提示词的各个组成部分（如角色设定、任务描述、上下文信息、具体问题、输出要求等）组织混乱，缺乏清晰的逻辑层次和分隔，模型在解析用户意图时就可能遇到困难，其输出的内容也可能显得杂乱无章，缺乏条理。使用分隔符、项目符号、编号列表等结构化元素有助于改善这一问题。<br>假设模型具有超强能力或实时信息 (Assuming Super Capabilities &#x2F; Real-time Data)：<br>用户有时会错误地假设大语言模型能够预测未来、读取思想、进行主观价值判断，或者拥有截至当前时刻的、完全实时的信息。这些都超出了当前主流LLM的能力范围。例如，要求模型“预测明天某支股票的价格”或“告诉我你对某个有争议社会问题的看法”通常是无效的。应将任务设计与模型已知的、基于其训练数据截止日期的能力范围相对齐。<br>不一致性与幻觉风险 (Inconsistency and Hallucination Risks)：<br>大语言模型在生成内容时，有时会表现出不一致性，即对于相似的输入可能给出不同的回答；更严重的是，它们有时会“一本正经地胡说八道”，即产生“幻觉”——捏造看似合理但实际上完全错误或不存在的信息。低效的提示词更容易诱发这些问题。可以通过提供清晰的指令、要求模型基于提供的参考文本进行回答、明确要求引用来源、使用思维链等技巧来努力减少幻觉的发生。<br>这些常见的提示词编写误区，在很大程度上源于用户未能充分理解大语言模型的工作方式——它们是基于海量文本数据训练出来的、强大的模式识别和概率预测机器，而非具备真正人类意义上的理解、常识和主动推理能力的实体。用户往往不自觉地将与人类进行自然、流畅、有时甚至是隐含式交流的习惯，直接套用在与模型的交互中，而忽略了模型对于明确、结构化指令的依赖。当提示词模糊不清、缺乏必要上下文、结构混乱，或者提出的要求超出了模型基于其训练数据所能合理推断的范围时，模型内部的“模式匹配”过程就很容易出错，或者在多个可能的模式之间产生歧义，最终导致输出结果不相关、不准确，甚至产生看似可信的“幻觉”信息。因此，避免这些误区的核心在于转变思维模式：从“与一个无所不知的人类专家交谈”转变为“向一个能力极强但有时过于‘字面化’、缺乏主动性的工具下达精确指令”。这要求我们在与LLM沟通时，采取一种更为审慎、更为结构化、也更为明确的方式。</p>
<h3 id="B-针对性改进方法与实践建议"><a href="#B-针对性改进方法与实践建议" class="headerlink" title="B. 针对性改进方法与实践建议"></a>B. 针对性改进方法与实践建议</h3><p>针对上述常见的低效提示词特征，可以采取一系列针对性的改进方法和实践建议，以显著提升提示词的质量和模型输出的效果。这些策略的核心在于“以模型为中心”进行思考，即深入理解模型处理信息的方式和潜在的“理解障碍”，并据此调整和优化提示词的表述与结构，使其更易于被模型“理解”和准确执行。<br>提升清晰度和具体性：<br>这是改进提示词最基本也是最重要的一环。应当使用明确无误的动词来指示任务，对所有的要求进行量化（例如，明确指出期望的字数范围、项目数量等），清晰定义所使用的术语（尤其是在涉及专业领域或可能存在歧义时），并且明确告知模型生成内容的目标受众以及期望的输出格式。例如，将一个模糊的指令“请解释气候变化”改进为一个更清晰具体的指令：“请用不超过200字的篇幅，解释自1950年以来，由人类活动引起的气候变化的主要原因及其对全球农业生产造成的显著影响，并请引用至少一项近五年内发表的相关研究作为佐证。”。<br>补充必要的上下文和背景信息：<br>确保在提示词中提供所有与任务相关的、必要的背景事实、数据、参考来源或先前的对话记录。如果任务是基于特定文档进行问答或分析，应明确指出该文档，并在可能的情况下（如上下文窗口允许）提供文档的关键内容或摘要。<br>简化复杂指令与任务分解：<br>当面临一个包含多个步骤、涉及多种约束或逻辑关系复杂的任务时，应避免将所有要求都堆砌在一个庞大而冗长的提示词中。更有效的方法是，将这个复杂的大任务分解为一系列更简单、更专注的子提示，然后通过串联（前一个子任务的输出作为后一个的输入）或并联（独立完成各子任务后汇总结果）的方式，引导模型逐步完成整个任务。<br>结构化提示词：<br>采用清晰的结构来组织提示词的各个组成部分，例如使用明确的分隔符（如三反引号 &#96;&#96;&#96;&#96;&#96;、###、XML标签 <context></context> 等）来区分指令区域、上下文信息区域、待处理输入数据区域和输出格式要求区域。在列举多个要点或步骤时，善用项目符号或编号列表。这种结构化的表达有助于模型准确解析和理解提示的意图。<br>提供示例 (Few-shot)：<br>对于需要模型遵循特定格式、风格或完成不常见任务的情况，在提示词中提供一到三个高质量的输入输出范例（即少样本提示），往往能极大地帮助模型“理解”任务的确切要求和期望的回答模式。<br>使用正面指令：<br>尽量告诉模型“应该做什么”，而不是仅仅告诉它“不应该做什么”。正面指令为模型提供了更清晰的行动方向，通常比负面约束更有效。<br>迭代测试与反馈循环：<br>将提示工程视为一个持续的实验过程。对初始提示词进行测试，仔细评估其产生的输出，然后根据评估结果进行有针对性的调整和优化，再进行下一轮测试。建立这样一个有效的反馈循环，并系统地记录不同版本提示词的效果，是不断提升输出质量的关键。<br>利用提示模式库和工具：<br>参考和借鉴已有的、被证明行之有效的提示模式库（Prompt Pattern Libraries），可以为特定类型的任务提供良好的起点和灵感。同时，利用版本控制工具来管理和追踪提示词的迭代变更，使用可视化工具来辅助分析提示词结构和模型注意力，也能提高提示工程的效率和质量。<br>通过识别并规避前述的常见低效提示词特征，并积极应用这些针对性的改进策略，用户可以显著提升与大语言模型交互的有效性。这些改进策略的共同之处在于，它们都试图通过增加提示词的明确性、结构性、上下文信息和示例引导，为模型提供更强的“信号”和更清晰的“路径指引”，从而帮助模型更准确地匹配其内部存储的知识和已习得的模式。而任务分解和迭代优化等方法，则是在与模型持续“互动”和“校准”的过程中，逐步精炼这些信号和路径，最终达到理想的输出效果。</p>
<p><strong>建议表格3：常见提示词编写误区及解决方案表</strong></p>
<table>
<thead>
<tr>
<th>常见误区 (Common Mistake)</th>
<th>表现与影响 (Symptoms &amp; Impact)</th>
<th>解决方案 (Solution Strategy)</th>
<th>改进示例 (Improved Example)</th>
<th>关键相关 Snippets</th>
</tr>
</thead>
<tbody><tr>
<td>模糊与含糊不清 (Ambiguity &amp; Vagueness)</td>
<td>模型输出不相关、宽泛或错误解读用户意图。</td>
<td>提高指令的清晰度和具体性，使用明确的词语和量化要求。</td>
<td>差：“写个故事。” 好：“写一个500字的科幻故事，主角是一个意外穿越到未来的历史学家，故事发生在一个反乌托邦社会。”</td>
<td>-</td>
</tr>
<tr>
<td>缺乏上下文 (Missing Context)</td>
<td>模型无法理解特定情境，输出通用答案，或无法利用用户提供的特定知识。</td>
<td>提供必要的背景信息、参考数据或相关文档。</td>
<td>差：“总结这份报告。” 好：“总结这份关于2023年第四季度公司在新能源汽车市场销售业绩的报告（报告文本见附件），重点分析Model Y的销售额同比增长率及其主要竞争对手的表现。”</td>
<td>-</td>
</tr>
<tr>
<td>过度复杂&#x2F;指令过多 (Over-complexity)</td>
<td>模型难以处理所有指令，可能忽略部分要求或产生混淆的输出。</td>
<td>将复杂任务分解为多个简单的子提示，或使用清晰的步骤指示。</td>
<td>差：“请总结这段文本，然后将其翻译成德语，接着提取其中的关键实体，并判断文本的整体情感倾向是积极、消极还是中性，最后再为这个德语译文生成一个不超过50词的摘要。” 好：（分解为多个prompt）1. 总结文本。2. 将上一步的总结翻译成德语…</td>
<td>-</td>
</tr>
<tr>
<td>忽视输出格式&#x2F;结构 (Ignoring Output Format)</td>
<td>模型输出格式随意，不便于后续处理或阅读，或不符合应用需求。</td>
<td>明确指定期望的输出格式（如JSON, Markdown, 列表, 表格）和结构。</td>
<td>差：“告诉我苹果和香蕉的营养成分。” 好：“请以JSON格式列出苹果和香蕉的主要营养成分，对每种水果，至少包含以下字段：水果名称 (name), 每100克含有的卡路里 (calories_per_100g), 蛋白质含量 (protein_g), 碳水化合物含量 (carbs_g), 脂肪含量 (fat_g)。”</td>
<td>-</td>
</tr>
<tr>
<td>假设模型具有实时信息或超能力 (Assuming Super Capabilities)</td>
<td>要求模型提供最新的、超出其训练数据截止日期的信息，或进行主观臆断性的预测。</td>
<td>明确模型的能力边界，不要求其提供超出预训练知识范围或实时性的信息。</td>
<td>差：“预测明天比特币的价格会是多少？” 好：“基于过去一年比特币的价格历史数据（数据见附表CSV文件），请分析其价格波动的主要模式和可能的驱动因素。”</td>
<td>-</td>
</tr>
<tr>
<td>使用负面指令 (Using Negative Instructions)</td>
<td>模型可能难以理解“不要做什么”的指令，反而会不恰当地关注到不希望出现的点。</td>
<td>使用正面指令，清晰、直接地告诉模型“应该做什么”。</td>
<td>差：“不要在回答中包含任何关于政治的敏感内容。” 好：“请在回答中专注于讨论该技术在发展方面的应用和潜力，并确保内容客观中立。”</td>
<td>-</td>
</tr>
</tbody></table>
<p>此表格为用户提供了一个实用的“避坑指南”和“改进手册”。通过直观地展示常见的提示词编写误区、它们可能导致的不良影响，以及相应的解决方案和具体的改进示例（同时标注了关键的文献来源），用户能够更容易地识别自己提示词中存在的问题，并有针对性地进行修正。这不仅有助于避免低效的反复试错，更能引导用户形成良好的提示词编写习惯，从而更高效地利用大语言模型的能力。</p>
<h2 id="七、提示词工程的场景化应用：开发与日常"><a href="#七、提示词工程的场景化应用：开发与日常" class="headerlink" title="七、提示词工程的场景化应用：开发与日常"></a>七、提示词工程的场景化应用：开发与日常</h2><p>提示词工程的策略和技巧，会因应用场景的不同而有所侧重。面向大模型应用开发者的提示词设计，与普通用户在日常生活中使用大模型时的提示技巧，在目标、复杂度、工具依赖和迭代方式上均存在显著差异。</p>
<h3 id="A-面向大模型应用开发者的提示词策略"><a href="#A-面向大模型应用开发者的提示词策略" class="headerlink" title="A. 面向大模型应用开发者的提示词策略"></a>A. 面向大模型应用开发者的提示词策略</h3><p>对于大模型应用的开发者而言，提示词工程不仅仅是与模型进行单次对话的优化，更是构建整个应用行为逻辑、确保用户体验一致性与可靠性的核心环节。其策略更侧重于系统化、可预测性、可维护性以及安全性。<br>系统提示 (System Prompts) 的设计与应用：<br>系统提示是由应用开发者预先设定好的、在用户与模型交互开始之前或贯穿整个交互过程中的基础性指令。它为AI模型提供了核心的行为框架、角色定位、上下文背景以及必须遵守的准则。系统提示对AI在应用内的整体行为具有广泛而持久的影响，是塑造AI应用“个性特征”和“行为边界”的关键手段。例如，在一个客服应用中，系统提示可以设定AI的角色为“一位始终保持礼貌、耐心且富有同理心的专业客服代表”，并规定其在回答用户问题时应遵循的特定流程或知识库范围。设计良好的系统提示需要清晰简洁地表达指令，审慎融入伦理考量以避免偏见或不当输出，并且需要根据应用反馈和需求变化进行定期的审查与更新。<br>为特定高级应用场景设计提示 (如RAG, AI Agents)：<br>在构建如检索增强生成（RAG）或AI智能体（AI Agents）这类更复杂的GenAI应用时，提示工程扮演着更为核心和精细的角色，通常需要配合严格的版本控制、全面的测试以及持续的验证机制。<br>RAG (Retrieval Augmented Generation)： 在RAG应用中，提示词的设计需要能够有效地整合从外部知识库检索到的相关上下文信息，并明确指示模型必须基于这些检索到的、通常更为实时和专业的上下文来回答用户的问题，而不是仅仅依赖其预训练的内部知识。例如，一个典型的RAG系统提示可能是：“请严格依据以下提供的段落内容来回答用户提出的问题。如果段落内容不足以回答，请明确指出。”。<br>AI Agents： 对于AI智能体，提示词则用于更为复杂的任务，如长期规划、多步骤任务分解、决策制定、外部工具的恰当调用（例如执行代码、查询API）、以及短期和长期记忆的管理与运用。例如，在ReAct（Reasoning and Acting）框架中，提示词被精心设计来引导模型在“思考（Thought）-行动（Action）-观察（Observation）”的循环中交错进行，从而完成需要与环境动态交互的复杂任务。<br>结构化与模板化提示：<br>为了确保应用在处理大量不同用户输入时仍能保持输出的一致性和可维护性，开发者倾向于使用模块化、可复用的提示模板。这些模板通常包含固定的指令结构和可动态填充的变量（例如，用户的具体问题、检索到的上下文等）。这种做法类似于软件开发中使用函数或类来封装通用逻辑，极大地提高了开发效率和应用的整体稳定性。<br>关注鲁棒性、安全性与可控性：<br>应用级别的提示词设计必须周全考虑到各种边缘情况和潜在的滥用风险。开发者需要设计提示来有效处理格式异常的用户输入，防范恶意的“提示注入”（Prompt Injection）攻击（即用户试图通过特殊输入来覆盖或操纵原始系统提示的意图），并确保模型的输出严格遵守相关的法律法规和伦理准则（例如，在金融领域的应用中，需要遵循“底线把控原则”，确保输出的合规性）。<br>应用开发中的提示工程，其核心目标是构建一个系统化、可预测、可维护且足够安全的交互逻辑。这超越了对单次对话效果的简单优化，而是深入到应用核心行为模式和整体用户体验的设计层面。应用开发追求的是能够稳定运行、可靠响应并可灵活扩展的系统。然而，大语言模型的输出本身具有内在的不确定性和概率性。因此，开发者必须通过更为精密和工程化的提示设计——例如精心构建的系统提示、细致的任务分解逻辑、严格的输入输出结构化、以及与外部工具和知识库的审慎集成——来最大限度地约束这种不确定性，引导LLM在预先设定的、可控的框架内行动。这不仅要求开发者对LLM的能力边界有深刻的理解，更需要他们具备将复杂的业务逻辑和交互需求准确无误地转化为LLM能够清晰理解并有效执行的指令序列的能力。从这个角度看，面向开发者的提示工程，是AI应用架构设计中不可或缺的核心组成部分，它需要一种更接近于传统软件工程的严谨思维，强调鲁棒性、可扩展性、安全性和与其他系统组件的无缝集成。</p>
<h3 id="B-面向普通用户的日常高效提示技巧"><a href="#B-面向普通用户的日常高效提示技巧" class="headerlink" title="B. 面向普通用户的日常高效提示技巧"></a>B. 面向普通用户的日常高效提示技巧</h3><p>对于非专业开发者，即广大的普通用户而言，在日常工作、学习或生活中与大语言模型进行交互时，掌握一些简单而高效的提示技巧，同样能够显著提升获取信息的质量和解决问题的效率。其策略更侧重于清晰沟通和有效提问，目标是快速获得满足个人即时需求的、有用的信息或内容。<br>清晰表达需求与目标：<br>向模型提问或下达指令时，应尽可能明确、具体地说明你希望模型做什么，避免使用模糊不清或过于宽泛的请求。例如，与其简单地说“讲讲艺术”，不如具体说明：“请解释一下什么是印象派绘画，它有哪些主要特点，并列举三位你认为最具代表性的印象派画家及其主要成就。”。<br>提供必要的上下文：<br>在提问或要求模型执行任务前，简要给出相关的背景信息，这能帮助模型更好地理解你的问题或任务所处的特定情境。例如，如果你想让模型推荐营销策略，与其泛泛地问“有什么好的营销策略？”，不如提供一些上下文：“我正在为一家新成立的、专注于开发教育类App的科技初创公司寻找早期用户获取的营销策略，你有什么建议吗？”。<br>指定期望的输出形式：<br>如果你对模型回答的长度（如“请限制在200字以内”）、格式（如“请用项目符号列出要点”、“请写成一封正式邮件的格式”）或风格（如“请用通俗易懂的语言解释”、“请模仿莎士比亚的风格”）有特定的期望，务必在提示词中明确说明。<br>使用少量示例进行引导 (Few-shot)：<br>当你希望模型模仿某种特定的回答风格、遵循某种不常见的格式，或者处理一个模型可能不太熟悉的新颖任务时，可以在提示词中给出1到2个清晰的输入输出示例。例如，在请求模型解释一个隐喻时，可以先提供一个包含隐喻的对话示例，并展示你期望的解释方式，然后再让模型解释新的隐喻。<br>尝试迭代和追问：<br>与LLM的交互往往是一个逐步求精的过程。如果初次得到的回答不完全符合你的预期，不要轻易放弃。可以尝试换一种提问的方式，或者针对回答中不满意、不清晰或遗漏的部分进行具体的追问和细化要求。例如，在模型生成了一份专业总结后，你可以继续追问：“很好，现在请把这份总结缩减到60个词以内。”或者“能用一种不那么正式、更口语化的语气重写一遍吗？”。<br>给予模型“思考时间”：<br>对于一些相对复杂的问题或需要多角度分析的任务，可以尝试在提示词中引导模型先进行一些内部的“思考”步骤或从不同方面进行考量，然后再给出最终的结论或答案。例如，可以明确指示：“请按照以下步骤来分析这段文本，并给出你的最终评估结果。第一步，用一句话概括文本的核心主题……”。<br>普通用户在使用大语言模型时，其主要目的通常是为了快速解决遇到的即时问题、获取所需信息或生成特定类型的内容。他们可能并不具备深厚的计算机科学或人工智能技术背景。因此，面向普通用户的高效日常提示技巧，其核心应在于简单易学、直观有效，侧重于如何将自然产生的想法和需求，清晰、准确地传达给LLM。关键在于提供足够的信息（任务是什么、为何需要、期望结果大致如何），并对期望的输出结果有一个基本的轮廓设想。与应用开发者相比，普通用户可能不需要过多关注提示词的底层结构设计、极端情况的容错处理或与其他系统的复杂集成，但同样需要掌握核心的清晰化表达和情境化沟通方法，才能让LLM成为一个真正有用且易于理解的个人助手。</p>
<p><strong>建议表格4：开发者 vs. 日常用户提示策略对比表</strong></p>
<table>
<thead>
<tr>
<th>策略维度 (Strategy Dimension)</th>
<th>面向应用开发者 (For Developers)</th>
<th>面向普通用户 (For Everyday Users)</th>
<th>目标差异 (Goal Difference)</th>
</tr>
</thead>
<tbody><tr>
<td>主要目标 (Primary Goal)</td>
<td>构建稳定、可预测、可扩展、安全的AI应用功能。</td>
<td>快速获取有用信息、生成特定内容、解决即时问题。</td>
<td>系统性构建 vs. 即时性需求满足。</td>
</tr>
<tr>
<td>提示复杂度 (Prompt Complexity)</td>
<td>通常较高，可能涉及多轮对话管理、结构化输入输出、模板化设计、条件逻辑判断。</td>
<td>通常较低，更偏向于使用自然语言进行直接的提问和指令下达。</td>
<td>需要处理各种潜在的用户输入和边缘情况 vs. 针对特定、相对简单的交互场景。</td>
</tr>
<tr>
<td>技术侧重 (Technical Focus)</td>
<td>系统提示设计、RAG集成、AI智能体构建、API接口交互、错误处理机制、安全性防护、可维护性、版本控制。</td>
<td>清晰表达需求、提供必要的上下文、指定期望的输出格式、通过迭代追问进行优化、利用少量示例引导。</td>
<td>工程化、系统化、鲁棒性优先 vs. 沟通效率、快速获得满意结果优先。</td>
</tr>
<tr>
<td>迭代与测试 (Iteration &amp; Testing)</td>
<td>严格的、数据驱动的迭代优化流程，常采用A&#x2F;B测试、自动化评估框架，关注客观性能指标。</td>
<td>相对非正式的、基于主观感受的迭代调整，通过观察输出效果来尝试不同的问法。</td>
<td>系统整体性能最优化 vs. 快速达到个人主观满意度。</td>
</tr>
<tr>
<td>工具使用 (Tool Usage)</td>
<td>专业的Prompt管理平台、版本控制系统（如Git）、自动化测试与评估工具、调试器。</td>
<td>主要是大语言模型应用本身提供的交互界面（如聊天框）。</td>
<td>专业化工具链支持 vs. 通用型用户界面。</td>
</tr>
<tr>
<td>对模型理解深度 (Depth of Model Understanding)</td>
<td>需要较深入地理解模型的能力边界、Token限制、API具体参数、潜在偏见等。</td>
<td>对模型能做什么有一个基本的、功能性的理解即可。</td>
<td>追求对模型行为的精确控制和预测 vs. 利用模型的通用能力完成任务。</td>
</tr>
</tbody></table>
<p>此对比表清晰地揭示了应用开发者与普通用户在运用提示工程时的核心差异。开发者在构建AI应用时，其提示词设计更像是一种系统工程，需要综合考虑应用的稳定性、可扩展性、安全性以及与其他系统的集成，因此会采用更复杂、更结构化、更具鲁棒性的提示策略，并借助专业的工具链进行严格的测试和迭代。而普通用户在日常使用中，其提示技巧则更侧重于如何通过清晰、直接的自然语言沟通，辅以必要的上下文和对输出形式的简单指定，来快速、高效地从LLM获取满足其即时需求的信息或内容。理解这些差异，有助于不同类型的用户群体根据自身的具体目标和场景，选择和应用最适合自己的提示词编写与优化方法，从而更有效地驾驭大语言模型。</p>
<h2 id="八、总结与展望"><a href="#八、总结与展望" class="headerlink" title="八、总结与展望"></a>八、总结与展望</h2><h3 id="A-高质量提示词编写的核心要点回顾"><a href="#A-高质量提示词编写的核心要点回顾" class="headerlink" title="A. 高质量提示词编写的核心要点回顾"></a>A. 高质量提示词编写的核心要点回顾</h3><p>撰写高质量的提示词是有效利用大语言模型（LLM）的关键。其核心在于通过清晰、具体、结构化的指令，为模型提供充足的上下文信息，并明确期望的输出形式。这要求我们不仅要准确表达自身意图，还要理解模型的工作方式，以便用模型“易于理解”的语言进行沟通。关键要素包括明确角色（Persona）、任务（Task）、指令（Instructions），提供必要的上下文（Context）和输入数据（Input Data），指定输出格式（Output Format），并在需要时给出示例（Examples&#x2F;Few-shot）进行引导。<br>遵循基本原则至关重要：力求清晰具体，避免模糊含糊；提供完整信息，确保上下文充分；语言简洁，避免不必要的冗余；保证语法、用词和标点的正确性；使用明确的行动动词；优先采用积极指令；并通过适当方式强调关键信息。对于复杂任务，有效的分解策略（如串联提示、并行子任务与汇总）能够显著提升模型处理能力和输出质量。<br>掌握核心的提示工程技术，如零样本与少样本提示、思维链（CoT）、思维树（ToT）、ReAct框架，以及自我一致性和反思&#x2F;自我批判等自我校正与迭代优化技术，能够进一步发掘LLM的潜力，应对更复杂的推理和交互场景。<br>最后，提示词的开发是一个持续迭代、不断优化的过程。通过系统性的测试、对模型输出的细致评估（结合人工评估、自动化指标、A&#x2F;B测试和LLM辅助评估），以及针对性的改进，才能逐步打磨出能够稳定产生高质量输出的提示词。</p>
<h3 id="B-提示词工程的未来发展趋势与新兴研究方向"><a href="#B-提示词工程的未来发展趋势与新兴研究方向" class="headerlink" title="B. 提示词工程的未来发展趋势与新兴研究方向"></a>B. 提示词工程的未来发展趋势与新兴研究方向</h3><p>提示词工程作为一个新兴且发展迅速的领域，其未来充满了机遇与挑战。随着大语言模型能力的不断增强和应用场景的持续拓展，对更高效、更智能、更安全的提示工程方法的需求也日益迫切。当前及未来的发展趋势和新兴研究方向主要包括：<br>自动化Prompt生成与优化： 手动设计和优化提示词既耗时又依赖经验。未来，利用AI技术来自动生成、评估和优化提示词将成为重要趋势。例如，Auto-CoT技术能够自动构建包含推理链的示例，而像Vertex AI Prompt Optimizer这样的工具则致力于通过算法自动调整和改进用户提供的原始提示。这将大大降低提示工程的门槛，提高开发效率。<br>多模态Prompting： 当前的提示主要以文本为主，但未来的LLM将更深入地融合对图像、声音、视频等多种模态信息的理解和生成能力。因此，如何设计能够有效整合和引导多模态输入的提示词，以及如何让模型生成丰富的多模态输出，将是重要的研究方向。<br>个性化与自适应Prompting： 未来的提示工程可能会更加关注个性化需求。系统可以根据用户的历史交互数据、已知的偏好、当前的上下文情境，甚至实时生理或情感状态，来动态地调整或生成最合适的提示词，从而提供高度定制化的用户体验。<br>更强的AI智能体与规划能力： 随着AI智能体（AI Agents）技术的发展，LLM将不仅仅是被动地响应提示，而是能够基于更高层次的目标进行自主规划、任务分解、工具调用和长期记忆管理。这对提示词的设计提出了新的要求：如何设定宏观目标、赋予智能体必要的自主权，同时又能确保其行为在可控和符合预期的范围内。<br>Prompt安全性与鲁棒性研究： 针对“提示注入”（Prompt Injection）、“越狱”（Jailbreaking）等试图绕过模型安全限制或使其产生不当输出的恶意攻击，以及如何提高提示词在面对各种噪声输入或意外情况时的鲁棒性，将是持续的研究热点。这涉及到设计更安全的提示框架、开发能识别和抵御恶意输入的机制等。<br>提示工程的标准化与最佳实践的普及： 随着领域的发展，将会出现更多关于提示词设计模式、评估标准、以及特定场景下最佳实践的总结和标准化工作。这将有助于知识的传播和整个社区技能水平的提升。<br>可解释性与可控性的增强： 用户不仅希望模型能给出好的结果，也越来越希望能理解模型为何会给出这样的结果，并能更精细地控制模型的行为。未来的提示工程可能会探索如何设计出能引导模型产生更具可解释性的推理过程，或者能让用户更容易干预和调整模型行为的提示技术。<br>综上所述，提示词工程正在从一门依赖直觉和经验的“手艺”，逐渐向一门更加系统化、理论化、工具化和科学化的“工程学科”演进。未来，它将更加注重自动化、智能化和安全性，并可能涉及人与AI之间更深层次的协作——例如，由AI工具辅助人类进行提示词的生成、评估和精炼，而人类则更专注于高层次的战略设计、目标设定和最终结果的监督与确认。这将为我们与大语言模型的交互开辟更广阔的可能性。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://missonix.github.io">Missonix</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://missonix.github.io/2024/02/12/Prompt%E6%8A%80%E5%B7%A7/">https://missonix.github.io/2024/02/12/Prompt%E6%8A%80%E5%B7%A7/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://missonix.github.io" target="_blank">Missonix</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Prompt/">Prompt</a><a class="post-meta__tags" href="/tags/LLM/">LLM</a></div><div class="post-share"><div class="social-share" data-image="/img/Missonix.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2023/09/29/VPS%E7%BD%91%E7%BB%9C%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%E5%8F%8A%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E4%B8%8E%E6%94%BB%E5%87%BB/" title="VPS网络代理服务器搭建及网络安全与攻击"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">VPS网络代理服务器搭建及网络安全与攻击</div></div><div class="info-2"><div class="info-item-1">基础网络知识参考该网络拓扑图 基础说明：IP地址是电脑主机(服务器)的地址，默认网关是局域网内路由器的地址，如果没有默认网关(路由器)那么 IP地址仅仅只能用于局域网内部的通信；有默认网关(连接路由器)后则主机发送数据(IP地址标识)给网关，网关将数据中转发送至目标主机，网关(路由器)是连接局域网内IP地址与公域网的桥梁。 TCP&#x2F;IP 四层模型四层模型指 应用层、传输层、网络层、数据链路层，除此之外最底部还有一个物理层应用层：HTTP、HTTPS协议及DNS解析在该层完成传输层：端口封装，TCP、UDP握手在该层完成网络层：IP地址封装，虚拟网卡的接入、ICMP在该层数据链路层：MAC地址的封装在该层完成 TCP三次握手(建立连接) 客户端 向 服务器发送消息报文请求连接，关键字段：SYN、ACK、顺序号、确认号、，客户端发送SYN&#x3D;1、ACK&#x3D;0、顺序号&#x3D;x； 服务器收到请求后，回复报文确定可以连接，服务端回复SYN&#x3D;1、ACK&#x3D;1、顺序号&#x3D;y、确认号&#x3D;x+1；...</div></div></div></a><a class="pagination-related" href="/2024/03/21/AI%E6%97%B6%E4%BB%A3%E5%AF%B9%E6%96%B0%E4%B8%80%E4%BB%A3%E5%B9%B3%E5%8F%B0%E7%A4%BE%E5%8C%BA%E6%B2%BB%E7%90%86%E8%80%85%E7%9A%84%E8%A6%81%E6%B1%82/" title="AI时代对新一代平台社区治理者的要求"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">AI时代对新一代平台社区治理者的要求</div></div><div class="info-2"><div class="info-item-1">AI时代对新一代平台社区治理者的要求1. 在社区安全治理领域具备精深的提示工程与LLM优化专业知识核心技术壁垒在于运用提示工程（PE）和LLM优化技术服务于社区安全目标。这要求不仅掌握PE的通用方法，更能将其创造性地应用于复杂多变的社区治理场景。 为内容审核设计、实验和优化提示词:必须能够精心制作特定、描述性和详尽的提示词，以引导LLM达成预期的审核结果。这包括指导LLM理解上下文、期望的输出格式、风格以及社区准则的细微之处。例如，OpenAI提出的最佳实践，如在提示开始时放置指令、使用特定分隔符、通过示例明确输出格式等，都是必备的技能 。 迭代方法论是关键，如从零样本（zero-shot）开始，逐步尝试少样本（few-shot）提示，并进行持续测试和优化，以“调试和引导模型的提示策略” 。需要具备设计实验来验证不同提示词版本效果的能力。 针对不同类型的网络危害（如仇恨言论、虚假信息、网络骚扰），提示工程需要考虑到语言的模糊性、讽刺、以及不断演变的俚语和表达方式所带来的挑战 。例如，仅仅告知模型“不要做什么”通常效果不佳，更有效的是明确指示模型“应该做什么”...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/05/09/LLM%E5%BA%94%E7%94%A8%E7%9A%84Bad-Case%E5%9B%9E%E6%B5%81%E7%AD%96%E7%95%A5/" title="LLM应用的Bad Case回流策略"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-09</div><div class="info-item-2">LLM应用的Bad Case回流策略</div></div><div class="info-2"><div class="info-item-1">AI大模型应用产品开发中的Bad Case回流策略设计I. 理解和分类LLM应用中的Bad CaseA. 定义“Bad Case”：超越简单错误在大语言模型（LLM）应用中，“Bad Case”并不仅仅指语法错误或简单的输出不正确；它涵盖了一系列可能削弱用户信任、导致有害结果或指示系统性缺陷的不良行为。这些行为包括输出事实不准确、不相关、带有偏见、有毒有害、不安全，或未能满足用户明确或隐含的意图。此外，它还包括LLM应用未能正确或高效执行其预定任务的功能性失败。 对“Bad Case”的定义必须结合应用的具体目的。例如，一个创意写作助手的模型，其事实性错误可能不如一个医疗诊断辅助工具中的同类错误那样关键 。因此，界定Bad Case需要充分考虑应用场景和潜在风险。 B. LLM失败模式的综合分类法建立一个健全的分类法是系统性处理Bad Case的第一步。此分类法应是多维度的，覆盖LLM性能和行为的各个方面。一个清晰、全面的分类法是任何Bad...</div></div></div></a><a class="pagination-related" href="/2024/03/21/AI%E6%97%B6%E4%BB%A3%E5%AF%B9%E6%96%B0%E4%B8%80%E4%BB%A3%E5%B9%B3%E5%8F%B0%E7%A4%BE%E5%8C%BA%E6%B2%BB%E7%90%86%E8%80%85%E7%9A%84%E8%A6%81%E6%B1%82/" title="AI时代对新一代平台社区治理者的要求"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-21</div><div class="info-item-2">AI时代对新一代平台社区治理者的要求</div></div><div class="info-2"><div class="info-item-1">AI时代对新一代平台社区治理者的要求1. 在社区安全治理领域具备精深的提示工程与LLM优化专业知识核心技术壁垒在于运用提示工程（PE）和LLM优化技术服务于社区安全目标。这要求不仅掌握PE的通用方法，更能将其创造性地应用于复杂多变的社区治理场景。 为内容审核设计、实验和优化提示词:必须能够精心制作特定、描述性和详尽的提示词，以引导LLM达成预期的审核结果。这包括指导LLM理解上下文、期望的输出格式、风格以及社区准则的细微之处。例如，OpenAI提出的最佳实践，如在提示开始时放置指令、使用特定分隔符、通过示例明确输出格式等，都是必备的技能 。 迭代方法论是关键，如从零样本（zero-shot）开始，逐步尝试少样本（few-shot）提示，并进行持续测试和优化，以“调试和引导模型的提示策略” 。需要具备设计实验来验证不同提示词版本效果的能力。 针对不同类型的网络危害（如仇恨言论、虚假信息、网络骚扰），提示工程需要考虑到语言的模糊性、讽刺、以及不断演变的俚语和表达方式所带来的挑战 。例如，仅仅告知模型“不要做什么”通常效果不佳，更有效的是明确指示模型“应该做什么”...</div></div></div></a><a class="pagination-related" href="/2025/01/26/LangChain%E5%9F%BA%E7%A1%80%E4%B8%8ERAG-Agent%E5%BC%80%E5%8F%91/" title="LangChain基础与RAG Agent开发"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-26</div><div class="info-item-2">LangChain基础与RAG Agent开发</div></div><div class="info-2"><div class="info-item-1">LangChain与RAG完整开发指南一、LangChain核心组件1.1 模型实例化123456789# 模型调用示例from langchain_openai import ChatOpenAImodel = ChatOpenAI(    openai_api_key=&quot;sk-xxx&quot;,    openai_api_base=&quot;&quot;,  # 支持国内模型    model_name=&quot;&quot;,    temperature=0.7,  # 控制生成随机性（0-1）    streaming=True    # 启用流式响应) 关键参数说明：  model_name: 支持主流模型如gpt-4、deepseek系列等 temperature: 值越大生成结果越随机 max_tokens: 控制生成内容的最大长度   1.2 提示词模板PromptTemplate 最基础的模板123456from langchain_core.prompts import PromptTemplateprompt_template =...</div></div></div></a><a class="pagination-related" href="/2025/05/09/%E7%94%B5%E5%95%86%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AF%84%E4%BC%B0%E7%AD%96%E7%95%A5/" title="电商智能客服系统的评估策略"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-09</div><div class="info-item-2">电商智能客服系统的评估策略</div></div><div class="info-2"><div class="info-item-1">电商智能客服系统中LoRA微调与RAG知识库应用的性能评估1. 电商领域复杂AI系统评估的基础原则在评估集成了LoRA（Low-Rank Adaptation）微调和大规模RAG（Retrieval-Augmented Generation）外挂商品知识库的电商智能客服系统时，建立一个坚实的评估基础至关重要。这不仅涉及到对底层大语言模型（LLM）能力的考量，更关乎整个应用系统在真实电商环境中的表现。 1.1....</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/Missonix.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Missonix</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">9</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">22</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/Missonix" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:ackerman0919@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%A9%BE%E9%A9%AD%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%9A%E9%AB%98%E8%B4%A8%E9%87%8F%E6%8F%90%E7%A4%BA%E8%AF%8D%EF%BC%88Prompt%EF%BC%89%E6%92%B0%E5%86%99%E6%8C%87%E5%8D%97"><span class="toc-number">1.</span> <span class="toc-text">驾驭大语言模型：高质量提示词（Prompt）撰写指南</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%BC%95%E8%A8%80%EF%BC%9A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E6%8F%90%E7%A4%BA%E8%AF%8D%EF%BC%88Prompt%EF%BC%89%E7%9A%84%E4%BB%B7%E5%80%BC"><span class="toc-number">1.1.</span> <span class="toc-text">一、引言：深入理解提示词（Prompt）的价值</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-%E6%8F%90%E7%A4%BA%E8%AF%8D%E7%9A%84%E5%AE%9A%E4%B9%89%E5%8F%8A%E5%85%B6%E5%9C%A8%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BA%A4%E4%BA%92%E4%B8%AD%E7%9A%84%E6%A0%B8%E5%BF%83%E4%BD%9C%E7%94%A8"><span class="toc-number">1.1.1.</span> <span class="toc-text">A. 提示词的定义及其在大模型交互中的核心作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-%E9%AB%98%E8%B4%A8%E9%87%8F%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%AF%B9%E4%BA%8E%E6%8F%90%E5%8D%87%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%87%BA%E6%95%88%E6%9E%9C%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7"><span class="toc-number">1.1.2.</span> <span class="toc-text">B. 高质量提示词对于提升大模型输出效果的重要性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E9%AB%98%E8%B4%A8%E9%87%8F%E6%8F%90%E7%A4%BA%E8%AF%8D%E7%9A%84%E5%9F%BA%E7%9F%B3%EF%BC%9A%E6%A0%B8%E5%BF%83%E8%A6%81%E7%B4%A0%E4%B8%8E%E5%9F%BA%E6%9C%AC%E5%8E%9F%E5%88%99"><span class="toc-number">1.2.</span> <span class="toc-text">二、高质量提示词的基石：核心要素与基本原则</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-%E5%AE%9A%E4%B9%89%E4%B8%8E%E8%A1%A1%E9%87%8F%EF%BC%9A%E4%BB%80%E4%B9%88%E6%98%AF%E2%80%9C%E9%AB%98%E8%B4%A8%E9%87%8F%E2%80%9D%E7%9A%84%E6%8F%90%E7%A4%BA%E8%AF%8D%EF%BC%9F"><span class="toc-number">1.2.1.</span> <span class="toc-text">A. 定义与衡量：什么是“高质量”的提示词？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-%E6%8F%90%E7%A4%BA%E8%AF%8D%E7%9A%84%E5%85%B3%E9%94%AE%E7%BB%84%E6%88%90%E9%83%A8%E5%88%86%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.2.2.</span> <span class="toc-text">B. 提示词的关键组成部分详解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#C-%E7%BC%96%E5%86%99%E9%AB%98%E6%95%88%E6%8F%90%E7%A4%BA%E8%AF%8D%E7%9A%84%E6%A0%B8%E5%BF%83%E5%8E%9F%E5%88%99"><span class="toc-number">1.2.3.</span> <span class="toc-text">C. 编写高效提示词的核心原则</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E7%BB%93%E6%9E%84%E5%8C%96%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%AE%BE%E8%AE%A1%EF%BC%9A%E6%8F%90%E5%8D%87%E6%B8%85%E6%99%B0%E5%BA%A6%E4%B8%8E%E5%8F%AF%E6%8E%A7%E6%80%A7"><span class="toc-number">1.3.</span> <span class="toc-text">三、结构化提示词设计：提升清晰度与可控性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-%E7%BB%93%E6%9E%84%E5%8C%96%E8%A1%A8%E8%BE%BE%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7"><span class="toc-number">1.3.1.</span> <span class="toc-text">A. 结构化表达的重要性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-%E6%9C%89%E6%95%88%E8%BF%90%E7%94%A8%E5%88%86%E9%9A%94%E7%AC%A6%E5%92%8C%E6%A0%BC%E5%BC%8F%E5%8C%96"><span class="toc-number">1.3.2.</span> <span class="toc-text">B. 有效运用分隔符和格式化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#C-%E5%A4%8D%E6%9D%82%E4%BB%BB%E5%8A%A1%E7%9A%84%E5%88%86%E8%A7%A3%E7%AD%96%E7%95%A5"><span class="toc-number">1.3.3.</span> <span class="toc-text">C. 复杂任务的分解策略</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E6%A0%B8%E5%BF%83%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.4.</span> <span class="toc-text">四、核心提示词工程技术详解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-%E5%9F%BA%E7%A1%80%E6%8A%80%E5%B7%A7%EF%BC%9A%E9%9B%B6%E6%A0%B7%E6%9C%AC%EF%BC%88Zero-shot%EF%BC%89%E4%B8%8E%E5%B0%91%E6%A0%B7%E6%9C%AC%EF%BC%88Few-shot%EF%BC%89%E6%8F%90%E7%A4%BA"><span class="toc-number">1.4.1.</span> <span class="toc-text">A. 基础技巧：零样本（Zero-shot）与少样本（Few-shot）提示</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-%E9%AB%98%E7%BA%A7%E6%8E%A8%E7%90%86%E6%8A%80%E6%9C%AF"><span class="toc-number">1.4.2.</span> <span class="toc-text">B. 高级推理技术</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#C-%E8%87%AA%E6%88%91%E6%A0%A1%E6%AD%A3%E4%B8%8E%E8%BF%AD%E4%BB%A3%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF"><span class="toc-number">1.4.3.</span> <span class="toc-text">C. 自我校正与迭代优化技术</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E6%8F%90%E7%A4%BA%E8%AF%8D%E7%9A%84%E8%BF%AD%E4%BB%A3%E5%BC%80%E5%8F%91%E4%B8%8E%E6%95%88%E6%9E%9C%E8%AF%84%E4%BC%B0"><span class="toc-number">1.5.</span> <span class="toc-text">五、提示词的迭代开发与效果评估</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-%E8%BF%AD%E4%BB%A3%E4%BC%98%E5%8C%96%E6%B5%81%E7%A8%8B%EF%BC%9A%E4%BB%8E%E5%88%9D%E6%AD%A5%E8%AE%BE%E8%AE%A1%E5%88%B0%E6%8C%81%E7%BB%AD%E6%94%B9%E8%BF%9B"><span class="toc-number">1.5.1.</span> <span class="toc-text">A. 迭代优化流程：从初步设计到持续改进</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-%E8%AF%84%E4%BC%B0%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%9C%89%E6%95%88%E6%80%A7%E7%9A%84%E6%96%B9%E6%B3%95%E4%B8%8E%E6%8C%87%E6%A0%87"><span class="toc-number">1.5.2.</span> <span class="toc-text">B. 评估提示词有效性的方法与指标</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E5%B8%B8%E8%A7%81%E6%8F%90%E7%A4%BA%E8%AF%8D%E7%BC%96%E5%86%99%E8%AF%AF%E5%8C%BA%E4%B8%8E%E6%94%B9%E8%BF%9B%E7%AD%96%E7%95%A5"><span class="toc-number">1.6.</span> <span class="toc-text">六、常见提示词编写误区与改进策略</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-%E8%AF%86%E5%88%AB%E4%BD%8E%E6%95%88%E6%8F%90%E7%A4%BA%E8%AF%8D%EF%BC%9A%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%89%96%E6%9E%90"><span class="toc-number">1.6.1.</span> <span class="toc-text">A. 识别低效提示词：常见问题剖析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-%E9%92%88%E5%AF%B9%E6%80%A7%E6%94%B9%E8%BF%9B%E6%96%B9%E6%B3%95%E4%B8%8E%E5%AE%9E%E8%B7%B5%E5%BB%BA%E8%AE%AE"><span class="toc-number">1.6.2.</span> <span class="toc-text">B. 针对性改进方法与实践建议</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E7%9A%84%E5%9C%BA%E6%99%AF%E5%8C%96%E5%BA%94%E7%94%A8%EF%BC%9A%E5%BC%80%E5%8F%91%E4%B8%8E%E6%97%A5%E5%B8%B8"><span class="toc-number">1.7.</span> <span class="toc-text">七、提示词工程的场景化应用：开发与日常</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-%E9%9D%A2%E5%90%91%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84%E6%8F%90%E7%A4%BA%E8%AF%8D%E7%AD%96%E7%95%A5"><span class="toc-number">1.7.1.</span> <span class="toc-text">A. 面向大模型应用开发者的提示词策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-%E9%9D%A2%E5%90%91%E6%99%AE%E9%80%9A%E7%94%A8%E6%88%B7%E7%9A%84%E6%97%A5%E5%B8%B8%E9%AB%98%E6%95%88%E6%8F%90%E7%A4%BA%E6%8A%80%E5%B7%A7"><span class="toc-number">1.7.2.</span> <span class="toc-text">B. 面向普通用户的日常高效提示技巧</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AB%E3%80%81%E6%80%BB%E7%BB%93%E4%B8%8E%E5%B1%95%E6%9C%9B"><span class="toc-number">1.8.</span> <span class="toc-text">八、总结与展望</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-%E9%AB%98%E8%B4%A8%E9%87%8F%E6%8F%90%E7%A4%BA%E8%AF%8D%E7%BC%96%E5%86%99%E7%9A%84%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E5%9B%9E%E9%A1%BE"><span class="toc-number">1.8.1.</span> <span class="toc-text">A. 高质量提示词编写的核心要点回顾</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E7%9A%84%E6%9C%AA%E6%9D%A5%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF%E4%B8%8E%E6%96%B0%E5%85%B4%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91"><span class="toc-number">1.8.2.</span> <span class="toc-text">B. 提示词工程的未来发展趋势与新兴研究方向</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/05/09/%E7%94%B5%E5%95%86%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AF%84%E4%BC%B0%E7%AD%96%E7%95%A5/" title="电商智能客服系统的评估策略">电商智能客服系统的评估策略</a><time datetime="2025-05-09T13:25:15.000Z" title="发表于 2025-05-09 21:25:15">2025-05-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/05/09/LLM%E5%BA%94%E7%94%A8%E7%9A%84Bad-Case%E5%9B%9E%E6%B5%81%E7%AD%96%E7%95%A5/" title="LLM应用的Bad Case回流策略">LLM应用的Bad Case回流策略</a><time datetime="2025-05-09T13:23:14.000Z" title="发表于 2025-05-09 21:23:14">2025-05-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/01/26/LangChain%E5%9F%BA%E7%A1%80%E4%B8%8ERAG-Agent%E5%BC%80%E5%8F%91/" title="LangChain基础与RAG Agent开发">LangChain基础与RAG Agent开发</a><time datetime="2025-01-26T15:01:13.000Z" title="发表于 2025-01-26 23:01:13">2025-01-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/04/13/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/" title="大模型常见问题及解决方案">大模型常见问题及解决方案</a><time datetime="2024-04-13T08:11:38.000Z" title="发表于 2024-04-13 16:11:38">2024-04-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/03/21/AI%E6%97%B6%E4%BB%A3%E5%AF%B9%E6%96%B0%E4%B8%80%E4%BB%A3%E5%B9%B3%E5%8F%B0%E7%A4%BE%E5%8C%BA%E6%B2%BB%E7%90%86%E8%80%85%E7%9A%84%E8%A6%81%E6%B1%82/" title="AI时代对新一代平台社区治理者的要求">AI时代对新一代平台社区治理者的要求</a><time datetime="2024-03-21T06:39:22.000Z" title="发表于 2024-03-21 14:39:22">2024-03-21</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Missonix</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.3</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div></div></body></html>